{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "CS224W - Colab1 Extension ",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuXWJLEm2UWS"
      },
      "source": [
        "# CS224W - Colab1 Extension "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gzsP50bF6Gb"
      },
      "source": [
        "In this notebook, we will implement a pipeline for **learning node embeddings** from scratch, and all the steps are as follows:\n",
        "\n",
        "1. Load a classic graph in network science, the [Karate Club Network](https://en.wikipedia.org/wiki/Zachary%27s_karate_club), which we've seen in Colab0. And, we will explore multiple graph statistics for that graph.\n",
        "2. Transform the graph structure into a PyTorch tensor, so that we can perform machine learning over the graph.\n",
        "3. Finish the first learning algorithm on graphs, a **node embedding** model, which's simpler than `DeepWalk` / `node2vec` algorithms taught in the lecture. \n",
        "\n",
        "Most of the work is copied from [CS224W - Colab1](https://colab.research.google.com/drive/1p2s0on6nibUYhJnONBWEAwpBlue37Tcc?usp=sharing).\n",
        "\n",
        "## Statement\n",
        "> To organize my thoughts, I think that running the notebook and trying to share some related supplementary resources would be a good way to go. Moreover, I hope that this work will help someone interested in the topics like **Machine Learning on Graphs** or **Graph Representation Learning**. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nwwq0nSdmsOL"
      },
      "source": [
        "# 1. Graph Basics\n",
        "To start, we will load a classic graph in network science, the [Karate Club Network](https://en.wikipedia.org/wiki/Zachary%27s_karate_club), which has been introduced in Colab0. We will explore multiple graph statistics for that graph."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDkpByYYfSzb"
      },
      "source": [
        "## Setup\n",
        "[NetworkX](https://networkx.org/documentation/stable/) is the main package used in this Colab. To recap or learn more about it, please refer to [Colab0 - Extension](https://github.com/JiangJiaWei1103/CS224W-Course-Practice/blob/master/CS224W_Colab0_Extension.ipynb). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWPkJjPAfVNW"
      },
      "source": [
        "import networkx as nx\n",
        "import random"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqUnYT5qUZYh"
      },
      "source": [
        "## Zachary's karate club network\n",
        "\n",
        "The [Karate Club Network](https://en.wikipedia.org/wiki/Zachary%27s_karate_club) is a graph describing a social network of 34 members of a karate club and documents links between members who interacted outside the club. Instead of using `PyTorch` to load in the complete dataset for deep learning on graph, we use `NetworkX` to load in the graph data and do some exploration."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIETqEfrfy5Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8de0860-09b7-4685-f439-7c1f3a210498"
      },
      "source": [
        "# Load in graph structure, Zachary's Karate Club\n",
        "G = nx.karate_club_graph()\n",
        "\n",
        "# Check properties of graph G\n",
        "print(f\"Graph G is directed: {G.is_directed()}\")\n",
        "print(f\"Following are node degrees of randomly selected five nodes...\")\n",
        "nodes = random.sample(range(G.number_of_nodes()), 5)\n",
        "print(\"Node Degree\")\n",
        "for node in nodes:\n",
        "    print(f\"{node:4} {G.degree(node):6}\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph G is directed: False\n",
            "Following are node degrees of randomly selected five nodes...\n",
            "Node Degree\n",
            "   7      4\n",
            "  23      5\n",
            "  31      6\n",
            "  12      2\n",
            "  27      4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDvf3nm-ors4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "154fb5b1-f5c0-4266-d692-4994550dca58"
      },
      "source": [
        "# Visualize the graph\n",
        "nx.draw(G, with_labels = True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FX25Y1CrYmgN"
      },
      "source": [
        "## Question 1: What is the average degree of the karate club network? (5 Points)\n",
        "\n",
        "### **Explanation in Detail**\n",
        "> To solve the problem, we should first check out what information is known. In this case, **number of edges** and **number of nodes** are given. And we also know that this graph is **undirected**. \n",
        "Hence, we conclude that one edge will contribute degree of **two**, *i.e.*, one for node u and the other for node v where u and v is connected by this edge."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUhES1VYo3tB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5babdf52-cf10-4774-baf7-010658a79fe9"
      },
      "source": [
        "def average_degree(num_edges, num_nodes):\n",
        "  # TODO: Implement this function that takes number of edges\n",
        "  # and number of nodes, and returns the average node degree of \n",
        "  # the graph. Round the result to nearest integer (for example \n",
        "  # 3.3 will be rounded to 3 and 3.7 will be rounded to 4)\n",
        "\n",
        "  avg_degree = 0\n",
        "\n",
        "  ############# Your code here ############\n",
        "  total_degree = num_edges * 2   # Sum of degrees of all nodes over the graph\n",
        "  avg_degree = total_degree / num_nodes\n",
        "  avg_degree = round(avg_degree, 0)\n",
        "  #########################################\n",
        "\n",
        "  return avg_degree\n",
        "\n",
        "num_edges = G.number_of_edges()\n",
        "num_nodes = G.number_of_nodes()\n",
        "avg_degree = average_degree(num_edges, num_nodes)\n",
        "print(\"Average degree of karate club network is {}\".format(avg_degree))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average degree of karate club network is 5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fk02fD4vYmZI"
      },
      "source": [
        "## Question 2: What is the average clustering coefficient of the karate club network? (5 Points)\n",
        "\n",
        "### **Explanation in Detail**\n",
        "> To solve the problem, let's recap the definition of **clustering coefficient**. It measures how connected node v's neighboring nodes are. In other words, it measures the ratio of number of existing edges to number of all potential edges among node v's neighbors. And we can write down the formula as follows:\n",
        "$$e_{v} = \\frac{\\#Edges\\ among\\ neighbors}{\\binom{k_v}{2}},\\ where\\ k_{v}\\ is\\ degree\\ of\\ node\\ v.$$\n",
        "\n",
        "> Instead of implementing the function from scratch, the problem requires us to call the appropriate function provided by `NetworkX`. Hence we can directly call function [average_clustering](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.approximation.clustering_coefficient.average_clustering.html#networkx.algorithms.approximation.clustering_coefficient.average_clustering) to do the estimation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k15XKEto1aYJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6bbaa42-a31c-47d5-99c5-52e353255624"
      },
      "source": [
        "from networkx.algorithms.approximation.clustering_coefficient import average_clustering\n",
        "\n",
        "def average_clustering_coefficient(G):\n",
        "  # TODO: Implement this function that takes a nx.Graph\n",
        "  # and returns the average clustering coefficient. Round \n",
        "  # the result to 2 decimal places (for example 3.333 will\n",
        "  # be rounded to 3.33 and 3.7571 will be rounded to 3.76)\n",
        "\n",
        "  avg_cluster_coef = 0\n",
        "\n",
        "  ############# Your code here ############\n",
        "  ## Note: \n",
        "  ## 1: Please use the appropriate NetworkX clustering function\n",
        "  avg_cluster_coef = average_clustering(G=G, trials=1000, seed=2021)   # Set seed to enable reproducibility\n",
        "  avg_cluster_coef = round(avg_cluster_coef, 2)\n",
        "  #########################################\n",
        "\n",
        "  return avg_cluster_coef\n",
        "\n",
        "avg_cluster_coef = average_clustering_coefficient(G)\n",
        "print(\"Average clustering coefficient of karate club network is {}\".format(avg_cluster_coef))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average clustering coefficient of karate club network is 0.57\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zghQ-AhXYmP4"
      },
      "source": [
        "## Question 3: What is the PageRank value for node 0 (node with id 0) after one PageRank iteration? (5 Points)\n",
        "\n",
        "### **Explanation in Detail**\n",
        "> `PageRank` is a **link analysis approach** to estimate the importance of nodes in the graph. The notion behind the scene is that  **in-links** can be seen as votes. And, in-links from important pages should count more. In this problem, we are asked to implement `PageRank` by *Google*'s solution. The concept is that at each step, random surfer has a probability of $\\beta$ to follow a link at random and $1 - \\beta$ to jump (teleport) to some random page. And we can write down the formula as follows: $$r_j = \\sum_{i \\rightarrow j} \\beta \\frac{r_i}{d_i} + (1 - \\beta) \\frac{1}{N}$$\n",
        "\n",
        "> Instead of estimating `PageRank` value for one node at a time, I use the concept of **stochastic adjacency matrix M** to compute all values at once. Then, a lookup of the given node is done to obtain the specified `PageRank` value. This method can be extended to the scenario where we want to get a more accurate approximation of `RageRank` values of all nodes. For more detailed information, please refer to [CS224W: Machine Learning with Graphs | 2021 | Lecture 4.1 - PageRank](https://www.youtube.com/watch?v=TU0ankRcHmo&list=PLoROMvodv4rPLKxIpqhjhPgdQy7imNkDn&index=10)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOGdWjNc6O7x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0886d2d1-8262-4f7e-a53c-cea8433c2bed"
      },
      "source": [
        "import numpy as np \n",
        "from networkx.linalg.graphmatrix import adjacency_matrix as adj\n",
        "\n",
        "def one_iter_pagerank(G, beta, r0, node_id):\n",
        "  # TODO: Implement this function that takes a nx.Graph, beta, r0 and node id.\n",
        "  # The return value r1 is one interation PageRank value for the input node.\n",
        "  # Please round r1 to 2 decimal places.\n",
        "\n",
        "  r1 = 0\n",
        "\n",
        "  ############# Your code here ############\n",
        "  ## Note: \n",
        "  ## 1: You should not use nx.pagerank\n",
        "  r0_vec = [r0 for _ in range(G.number_of_nodes())]   # Initialize rank vector\n",
        "  \n",
        "  # Compute stochastic adjacency matrix M\n",
        "  adj_matrix = adj(G).toarray()\n",
        "  out_links = [G.degree[v] for v in G.nodes]   # Number of out-links of each node \n",
        "  col_stoch_matix = np.divide(adj_matrix, out_links)\n",
        "  \n",
        "  # Estimate PageRank values\n",
        "  pr_link = np.matmul(col_stoch_matix, r0_vec)[node_id]\n",
        "  pr_teleport = r0\n",
        "  r1 = beta * pr_link + (1-beta) * pr_teleport\n",
        "  r1 = round(r1, 2)\n",
        "  #########################################\n",
        "\n",
        "  return r1\n",
        "\n",
        "beta = 0.8\n",
        "r0 = 1 / G.number_of_nodes()\n",
        "node = 0\n",
        "r1 = one_iter_pagerank(G, beta, r0, node)\n",
        "print(\"The PageRank value for node 0 after one iteration is {}\".format(r1))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The PageRank value for node 0 after one iteration is 0.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icTcOULeYmIu"
      },
      "source": [
        "## Question 4: What is the (raw) closeness centrality for the karate club network node 5? (5 Points)\n",
        "\n",
        "### **Explanation in Detail**\n",
        "> `Closeness centrality` uses the sum of shortest path lengths to all other nodes to measure the importance of a node. The larger the value (*i.e.*, small sum of lengths) is, the more important that node is. Hence, we can understand why we need to take the reciprocal in the formula, which can be written down as follows: $$c(v) = \\frac{1}{\\sum_{u \\neq v}\\text{shortest path length between } u \\text{ and } v}$$\n",
        "\n",
        "> Instead of using the function [closeness_centrality](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.centrality.closeness_centrality.html?highlight=closeness_centrality#networkx.algorithms.centrality.closeness_centrality), I first calculate the sum of shortest path lengths using function [shortest_path_length](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.shortest_paths.generic.shortest_path_length.html#networkx.algorithms.shortest_paths.generic.shortest_path_length), then take the reciprocal. Notice that the difference between the raw centrality implemented below and the normalized one (see [closeness_centrality](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.centrality.closeness_centrality.html?highlight=closeness_centrality#networkx.algorithms.centrality.closeness_centrality)) is a factor $(n-1)$, which is included in the formula as follows: $$c(v)_{normalized} = \\frac{n-1}{\\sum_{u \\neq v}\\text{shortest path length between } u \\text{ and } v},\\ where\\ n\\ is\\ the\\ number\\ of\\ nodes\\ that\\ can\\ reach\\ node\\ v.$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbCsq_tl-3ok",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d99acb03-b949-4b08-c260-575613ad4dd9"
      },
      "source": [
        "from networkx.algorithms.shortest_paths.generic import shortest_path_length\n",
        "\n",
        "def closeness_centrality(G, node=5):\n",
        "  # TODO: Implement the function that calculates closeness centrality \n",
        "  # for a node in karate club network. G is the input karate club \n",
        "  # network and node is the node id in the graph. Please round the \n",
        "  # closeness centrality result to 2 decimal places.\n",
        "\n",
        "  closeness = 0\n",
        "\n",
        "  ## Note:\n",
        "  ## 1: You can use networkx closeness centrality function.\n",
        "  ## 2: Notice that networkx closeness centrality returns the normalized \n",
        "  ## closeness directly, which is different from the raw (unnormalized) \n",
        "  ## one that we learned in the lecture.\n",
        "  total_len = 0\n",
        "  shortest_path_lengths = shortest_path_length(G, source=node)\n",
        "  for n, l in shortest_path_lengths.items():\n",
        "      total_len += l\n",
        "  closeness = 1 / total_len \n",
        "  closeness = round(closeness, 2)\n",
        "  #########################################\n",
        "\n",
        "  return closeness\n",
        "\n",
        "node = 5\n",
        "closeness = closeness_centrality(G, node=node)\n",
        "print(\"The node 5 has closeness centrality {}\".format(closeness))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The node 5 has closeness centrality 0.01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MxvowibYl4x"
      },
      "source": [
        "# 2 Graph to Tensor\n",
        "We will then work together to transform the graph $G$ into a PyTorch tensor, so that we can perform machine learning over the graph."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDA8PosrA-9V"
      },
      "source": [
        "## Setup\n",
        "Check if PyTorch is properly installed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntuPVat_BAf1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b966008-276b-446f-eb72-6413957855f3"
      },
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.9.0+cu111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fko_2wSKYlun"
      },
      "source": [
        "## PyTorch tensor basics\n",
        "\n",
        "We can generate PyTorch tensor with all zeros, ones or random values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2ySw3m-A9qF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "121c4800-2732-447d-9f8f-d39b15a973ed"
      },
      "source": [
        "# Generate 3 x 4 tensor with all ones\n",
        "ones = torch.ones(3, 4)\n",
        "print(ones)\n",
        "\n",
        "# Generate 3 x 4 tensor with all zeros\n",
        "zeros = torch.zeros(3, 4)\n",
        "print(zeros)\n",
        "\n",
        "# Generate 3 x 4 tensor with random values on the interval [0, 1)\n",
        "random_tensor = torch.rand(3, 4)\n",
        "print(random_tensor)\n",
        "\n",
        "# Get the shape of the tensor\n",
        "print(ones.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]])\n",
            "tensor([[0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.]])\n",
            "tensor([[0.7853, 0.3507, 0.8405, 0.2013],\n",
            "        [0.1071, 0.3467, 0.4934, 0.0626],\n",
            "        [0.9275, 0.8237, 0.2666, 0.2946]])\n",
            "torch.Size([3, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8mp66eHBxWC"
      },
      "source": [
        "PyTorch tensor contains elements for a single data type, the `dtype`. Furthermore, each `dtype` has its own CPU and GPU variants. For more detailed information, please refer to [torch.Tensor](https://pytorch.org/docs/stable/tensors.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQiOvKJJBwq4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5015823-9239-426d-e60a-e14650353821"
      },
      "source": [
        "# Create a 3 x 4 tensor with all 32-bit floating point zeros\n",
        "zeros = torch.zeros(3, 4, dtype=torch.float32)\n",
        "print(zeros.dtype)\n",
        "\n",
        "# Change the tensor dtype to 64-bit integer\n",
        "zeros = zeros.type(torch.long)\n",
        "print(zeros.dtype)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32\n",
            "torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9EfegIRDkk2"
      },
      "source": [
        "## Question 5: Get the edge list of the karate club network and transform it into `torch.LongTensor`. What is the `torch.sum` value of `pos_edge_index` tensor? (10 Points)\n",
        "\n",
        "### **Explanation in Detail**\n",
        "> To solve this problem, we only need to know some basic operations provided by `NetworkX` and `PyTorch`. In function `graph_to_edge_list`, edges of graph $G$ are extracted out using $G$'s property, edges. In the second function `edge_list_to_tensor`, we should remember to **transpose** the tensor to meet the requirement of the problem. I use function `transpose` here, and there's another method to transpose a tensor, called `permute`. For more detailed information, please refer to [torch.transpose](https://pytorch.org/docs/stable/generated/torch.transpose.html) and [torch.permute](https://pytorch.org/docs/stable/generated/torch.Tensor.permute.html?highlight=torch%20permute)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEtVxMFID3ZT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73217669-0906-4dd6-c5b1-a35caa47be1f"
      },
      "source": [
        "def graph_to_edge_list(G):\n",
        "  # TODO: Implement the function that returns the edge list of\n",
        "  # an nx.Graph. The returned edge_list should be a list of tuples\n",
        "  # where each tuple is a tuple representing an edge connected \n",
        "  # by two nodes.\n",
        "\n",
        "  edge_list = []\n",
        "\n",
        "  ############# Your code here ############\n",
        "  for edge in G.edges(data=False):\n",
        "      edge_list.append(edge)\n",
        "  #########################################\n",
        "\n",
        "  return edge_list\n",
        "\n",
        "def edge_list_to_tensor(edge_list):\n",
        "  # TODO: Implement the function that transforms the edge_list to\n",
        "  # tensor. The input edge_list is a list of tuples and the resulting\n",
        "  # tensor should have the shape [2 x len(edge_list)].\n",
        "\n",
        "  edge_index = torch.tensor([])\n",
        "\n",
        "  ############# Your code here ############\n",
        "  edge_index = torch.tensor(edge_list, dtype=torch.long)\n",
        "  edge_index = torch.transpose(edge_index, 0, 1)\n",
        "  #########################################\n",
        "\n",
        "  return edge_index\n",
        "\n",
        "pos_edge_list = graph_to_edge_list(G)\n",
        "pos_edge_index = edge_list_to_tensor(pos_edge_list)\n",
        "print(\"The pos_edge_index tensor has shape {}\".format(pos_edge_index.shape))\n",
        "print(\"The pos_edge_index tensor has sum value {}\".format(torch.sum(pos_edge_index)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The pos_edge_index tensor has shape torch.Size([2, 78])\n",
            "The pos_edge_index tensor has sum value 2535\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBL-ZmdHWqIu"
      },
      "source": [
        "## Question 6: Please implement following function that samples negative edges. Then answer which edges (edge_1 to edge_5) can be potential negative edges in the karate club network? (10 Points)\n",
        "\n",
        "### **Explanation in Detail**\n",
        "> To solve this problem, we need to clarify what negative edges mean. **Negative edges** are edges that don't exist in graph $G$. Following are the explanations of two parts: <br>\n",
        "1. Because graph $G$ is **undirected**, I generate all negative edges $(i, j)'s\\ with\\ i < j$, which avoids the existence of duplicated edges in sampled negative edge list. Then, a random sampling is done with the specified number of negative edges. <br>\n",
        "We can also solve the problem from the perspective of adjacency matrix, which is **symmetric** in this case. Negative edges are those $(row, col)$ pairs with zero values residing in the **upper triangular adjacency matrix without diagonal (self loops)**. Then, negative edges can be randomly sampled from these positions.\n",
        "2. Again, we know that graph $G$ is **undirected**, so I write a function `check_neg` to determine whether the specified edge is in graph or not by representing edges as **node pairs (sets)**. And the determination is done by iteratively comparing all the existing edges in the graph with the specified edge (*i.e.*, second argument of function `check_neg`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9N8VT1f8-IJ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76506f5f-c2ac-4a5a-fc0d-a5fa18cb12f0"
      },
      "source": [
        "import random\n",
        "\n",
        "def sample_negative_edges(G, num_neg_samples):\n",
        "  # TODO: Implement the function that returns a list of negative edges.\n",
        "  # The number of sampled negative edges is num_neg_samples. You do not\n",
        "  # need to consider the corner case when the number of possible negative edges\n",
        "  # is less than num_neg_samples. It should be ok as long as your implementation \n",
        "  # works on the karate club network. In this implementation, self loops should \n",
        "  # not be considered as either a positive or negative edge. Also, notice that \n",
        "  # the karate club network is an undirected graph, if (0, 1) is a positive \n",
        "  # edge, do you think (1, 0) can be a negative one?\n",
        "\n",
        "  neg_edge_list = []\n",
        "\n",
        "  ############# Your code here ############\n",
        "  n_nodes = G.number_of_nodes()\n",
        "  neg_edges = []\n",
        "  for i in range(n_nodes):\n",
        "    for j in range(i+1, n_nodes):\n",
        "      if j not in G.neighbors(i):\n",
        "        neg_edges.append((i, j))\n",
        "  neg_edge_list = random.sample(neg_edges, num_neg_samples)\n",
        "  #########################################\n",
        "\n",
        "  return neg_edge_list\n",
        "\n",
        "# Sample 78 negative edges\n",
        "neg_edge_list = sample_negative_edges(G, len(pos_edge_list))\n",
        "\n",
        "# Transform the negative edge list to tensor\n",
        "neg_edge_index = edge_list_to_tensor(neg_edge_list)\n",
        "print(\"The neg_edge_index tensor has shape {}\".format(neg_edge_index.shape))\n",
        "\n",
        "# Which of following edges can be negative ones?\n",
        "edge_1 = (7, 1)\n",
        "edge_2 = (1, 33)\n",
        "edge_3 = (33, 22)\n",
        "edge_4 = (0, 4)\n",
        "edge_5 = (4, 2)\n",
        "\n",
        "############# Your code here ############\n",
        "## Note:\n",
        "## 1: For each of the 5 edges, print whether it can be negative edge\n",
        "def check_neg(G, edge):\n",
        "    '''Check if the edge is negative edge or not.\n",
        "    \n",
        "    Parameters:\n",
        "        edge: tuple, the specified node pair\n",
        "    \n",
        "    Return:\n",
        "        neg: boolean, if the specified node pair is negative edge or not\n",
        "    '''\n",
        "    neg = True\n",
        "    for p_edge in G.edges(data=False):\n",
        "        if set(p_edge) == set(edge):\n",
        "            neg = False\n",
        "    return neg\n",
        "    \n",
        "for i, edge in enumerate([edge_1, edge_2, edge_3, edge_4, edge_5]):\n",
        "    ind = 'is' if check_neg(G, edge) else 'isn\\'t'\n",
        "    print(f\"edge_{i+1} {ind} negative!\")\n",
        "#########################################"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The neg_edge_index tensor has shape torch.Size([2, 78])\n",
            "edge_1 isn't negative!\n",
            "edge_2 is negative!\n",
            "edge_3 isn't negative!\n",
            "edge_4 isn't negative!\n",
            "edge_5 is negative!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wk9Q-a-9qGsw"
      },
      "source": [
        "# 3 Node Emebedding Learning\n",
        "\n",
        "Finally, we will finish the first learning algorithm on graphs: a node embedding model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDBxRQcZ_dUH"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lnqn9H6s_ehX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c2e7788-bc8d-410d-acde-3ae597bbfbfe"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "print(torch.__version__)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.9.0+cu111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gomAf8vxq0R"
      },
      "source": [
        "To write our own node embedding learning methods, we'll heavily use the [`nn.Embedding`](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html) module in PyTorch. An embedding layer can be seen as a **trainable** version of **lookup table** (*i.e.*, embedding matrix) storing embedding vectors of the corresponding items (*e.g.*, nodes in a  graph). Let's see how to use `nn.Embedding`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRiWGuLAx5yx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f6cc7d2-1f72-42b2-c3d2-647dabfe31d1"
      },
      "source": [
        "# Initialize an embedding layer\n",
        "# Suppose we want to have embedding for 4 items (e.g., nodes)\n",
        "# Each item is represented with 8 dimensional vector\n",
        "\n",
        "emb_sample = nn.Embedding(num_embeddings=4, embedding_dim=8)\n",
        "print('Sample embedding layer: {}'.format(emb_sample))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample embedding layer: Embedding(4, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bS9qQfeujEVh"
      },
      "source": [
        "We can select items from the embedding matrix, by using Tensor indices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AGIfP4QEDr8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70aac630-09df-41e0-aded-787760119910"
      },
      "source": [
        "# Select an embedding in emb_sample\n",
        "id = torch.LongTensor([1])\n",
        "print(emb_sample(id))\n",
        "\n",
        "# Select multiple embeddings\n",
        "ids = torch.LongTensor([1, 3])\n",
        "print(emb_sample(ids))\n",
        "\n",
        "# Get the shape of the embedding weight matrix\n",
        "shape = emb_sample.weight.data.shape\n",
        "print(shape)\n",
        "\n",
        "# Overwrite the weight to tensor with all ones\n",
        "emb_sample.weight.data = torch.ones(shape)\n",
        "\n",
        "# Let's check if the emb is indeed initilized\n",
        "ids = torch.LongTensor([0, 3])\n",
        "print(emb_sample(ids))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.3176, -1.0541, -0.3292,  1.5619,  0.3604, -0.3348,  0.4754, -0.5614]],\n",
            "       grad_fn=<EmbeddingBackward>)\n",
            "tensor([[ 0.3176, -1.0541, -0.3292,  1.5619,  0.3604, -0.3348,  0.4754, -0.5614],\n",
            "        [-1.4761, -0.5862,  1.3527,  0.2054, -0.3388, -0.5045, -0.4699, -0.7523]],\n",
            "       grad_fn=<EmbeddingBackward>)\n",
            "torch.Size([4, 8])\n",
            "tensor([[-1.6586, -0.6491, -0.6770,  0.5875,  1.5732, -1.2892,  0.8566,  0.8722],\n",
            "        [ 0.3176, -1.0541, -0.3292,  1.5619,  0.3604, -0.3348,  0.4754, -0.5614],\n",
            "        [-0.6856,  1.1770, -0.7875,  0.9414, -1.2594,  1.1471,  0.9733, -1.4087],\n",
            "        [-1.4761, -0.5862,  1.3527,  0.2054, -0.3388, -0.5045, -0.4699, -0.7523]])\n",
            "tensor([[1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1.]], grad_fn=<EmbeddingBackward>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MjBuDKaKIsM"
      },
      "source": [
        "Now, it's your time to create node embedding matrix for the graph we have!\n",
        "- We want to have **16 dimensional** vector for each node in the karate club network.\n",
        "- We want to initalize the matrix under **uniform distribution**, in the range of $[0, 1)$. We suggest you using [`torch.rand`](https://pytorch.org/docs/stable/generated/torch.rand.html).\n",
        "\n",
        "### **Explanation in Detail** \n",
        "> To generate an embedding layer with initial weights under **uniform distribution**, we first initialize an embedding layer with the specified number of items (*i.e.*, nodes) and dimension of each embedding vector under. However, this weight matrix is initialized from $N(0, 1)$, so we need to reassign weights sampled from **uniform distribution** using `torch.rand` to the embedding layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMszSwRPKGn1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64bc5461-a99f-4910-f2d6-ceba5e51570c"
      },
      "source": [
        "# Please do not change / reset the random seed\n",
        "torch.manual_seed(1)\n",
        "\n",
        "def create_node_emb(num_node=34, embedding_dim=16):\n",
        "  # TODO: Implement this function that will create the node embedding matrix.\n",
        "  # A torch.nn.Embedding layer will be returned. You do not need to change \n",
        "  # the values of num_node and embedding_dim. The weight matrix of returned \n",
        "  # layer should be initialized under uniform distribution. \n",
        "\n",
        "  emb = None\n",
        "\n",
        "  ############# Your code here ############\n",
        "  emb = nn.Embedding(num_embeddings=num_node, embedding_dim=embedding_dim)\n",
        "  weights_uniform = torch.rand(num_node, embedding_dim)\n",
        "  emb.weight.data = weights_uniform\n",
        "  #########################################\n",
        "\n",
        "  return emb\n",
        "\n",
        "emb = create_node_emb()\n",
        "ids = torch.LongTensor([0, 3])\n",
        "\n",
        "# Print the embedding layer\n",
        "print(\"Embedding: {}\".format(emb))\n",
        "\n",
        "# An example that gets the embeddings for node 0 and 3\n",
        "print(emb(ids))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding: Embedding(34, 16)\n",
            "tensor([[0.2114, 0.7335, 0.1433, 0.9647, 0.2933, 0.7951, 0.5170, 0.2801, 0.8339,\n",
            "         0.1185, 0.2355, 0.5599, 0.8966, 0.2858, 0.1955, 0.1808],\n",
            "        [0.7486, 0.6546, 0.3843, 0.9820, 0.6012, 0.3710, 0.4929, 0.9915, 0.8358,\n",
            "         0.4629, 0.9902, 0.7196, 0.2338, 0.0450, 0.7906, 0.9689]],\n",
            "       grad_fn=<EmbeddingBackward>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QfoANibTzyh"
      },
      "source": [
        "## Visualize the initial node embeddings\n",
        "One good way to understand an embedding matrix, is to visualize it in a 2D space.\n",
        "Here, we have implemented an embedding visualization function for you.\n",
        "We first do PCA to reduce the dimensionality of embeddings to a 2D space.\n",
        "Then we visualize each point, colored by the community it belongs to."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LCoIkarhfYD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "2e9c1ab1-29c5-413d-bf21-71ec7301db19"
      },
      "source": [
        "def visualize_emb(emb):\n",
        "  X = emb.weight.data.numpy()\n",
        "  pca = PCA(n_components=2)\n",
        "  components = pca.fit_transform(X)\n",
        "  plt.figure(figsize=(6, 6))\n",
        "  club1_x = []\n",
        "  club1_y = []\n",
        "  club2_x = []\n",
        "  club2_y = []\n",
        "  for node in G.nodes(data=True):\n",
        "    if node[1]['club'] == 'Mr. Hi':\n",
        "      club1_x.append(components[node[0]][0])\n",
        "      club1_y.append(components[node[0]][1])\n",
        "    else:\n",
        "      club2_x.append(components[node[0]][0])\n",
        "      club2_y.append(components[node[0]][1])\n",
        "  plt.scatter(club1_x, club1_y, color=\"red\", label=\"Mr. Hi\")\n",
        "  plt.scatter(club2_x, club2_y, color=\"blue\", label=\"Officer\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "# Visualize the initial random embeddding\n",
        "visualize_emb(emb)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAFlCAYAAADoPlOZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAfIklEQVR4nO3df7BfdX3n8ec7wRgjUn5lkCXc3MiGrVEglDvU1dGiQBsZJ2FasEkvlh92s9a1da1sN53sOJZOulrt4uyU1qaKgnsXFHaV7IhD+SFTXYTlMkYUEBJoEi8FSRNrh7kFjHnvH+fc8M3le3N/fM/9/jrPx8yd7/d8zvl+z+eefPO6n+/nnPP5RGYiSep/CzpdAUlSexj4klQTBr4k1YSBL0k1YeBLUk0Y+JJUE0d1ugJTOfHEE3NwcLDT1ZCknvLQQw/9Y2YubbauawN/cHCQ0dHRTldDknpKROyeap1dOpJUEwa+JNWEgS9JNdG1ffiS1OhnP/sZY2NjvPDCC52uSldYvHgxy5Yt41WvetWMX2PgS+oJY2NjvO51r2NwcJCI6HR1Oioz2bdvH2NjY6xYsWLGr7NLR1JPeOGFFzjhhBNqH/YAEcEJJ5ww6287lQR+RKyJiMcjYmdEbGqyfiAivhkR342IhyPioir2K6leDPuXzeVYtBz4EbEQuA54N7AK2BARqyZt9l+Ar2Tm2cB64C9b3a8ktVtEcNlllx1aPnDgAEuXLuU973nPrN7nvPPOO+w+o127dvHmN78ZgNHRUX7/93+/mgpPUkUf/rnAzsx8CiAibgbWAY82bJPAMeXzXwD+oYL9SlJbvfa1r+UHP/gB//Iv/8JrXvMa7rzzTk455ZSm2x44cICjjpp9xA4NDTE0NNRqVZuqokvnFOBHDctjZVmjjwOXRcQYcDvwexXsV+pJIyMwOAgLFhSPIyOdrlGfmqcDfdFFF/H1r38dgJtuuokNGzYcWvfxj3+c973vfbztbW/jfe9735ze/9577531N4aZatdVOhuAL2bmn0fEvwW+FBFvzsyDjRtFxEZgI8DAwECbqia1z8gIbNwI4+PF8u7dxTLA8HDn6tV35vFAr1+/nmuuuYb3vOc9PPzww1x11VV861vfOrT+0Ucf5dvf/javec1rjvg+w8PDh7Z56aWXWLBg/q+hqWIPTwOnNiwvK8savR/4CkBmfgdYDJw4+Y0yc2tmDmXm0NKlTcf+kXra5s0vZ9CE8fGiXBWaxwN95plnsmvXLm666SYuuuiV15+sXbt22rAHGBkZYfv27Wzfvp3bb7+95XrNRBWB/yCwMiJWRMQiipOy2yZtswc4HyAi3kgR+Hsr2LfUU/bsmV255mieD/TatWu5+uqrD+vOmfDa1762kn3Mh5a7dDLzQER8CLgDWAhcn5mPRMQ1wGhmbgM+CvxNRHyE4gTuFZmZre5b6jUDA0XvQrNyVWieD/RVV13FscceyxlnnMG9995byXu2QyWdRpl5e2aenpmnZeaWsuxjZdiTmY9m5tsy86zMXJ2Zf1vFfqVes2ULLFlyeNmSJUW5KjTPB3rZsmUzunRy9erVleyvKtGtDe2hoaF0PHz1o5GRoit5z56iwblliydsZ+Kxxx7jjW9848xfUIMD3eyYRMRDmdn0uk7H0pHabHi473KnO3mgX8GxdCSpJgx8SaoJA1+SasLAl6SaMPAlqSYMfEmaobGxMdatW8fKlSs57bTT+PCHP8xLL70EwIYNGzjzzDO59tpr+eEPf8jq1as5++yzefLJJ3nrW9/a4ZoXDHxJmoHM5Nd//de5+OKL2bFjB0888QTPP/88mzdv5tlnn+XBBx/k4Ycf5iMf+Qhf+9rXuOSSS/jud7/Laaedxn333dfy/g8cONDyexj4kvpS1aMj33PPPSxevJgrr7wSgIULF3Lttddy/fXX8453vIOnn36a1atX88d//Md85jOf4a/+6q945zvfCcDRRx996H0++clPcsYZZ3DWWWexaVMxQeCTTz7JmjVrOOecc3j729/OD3/4QwCuuOIKPvCBD/DLv/zL/OEf/mFrvwDeeCWpD83H6MiPPPII55xzzmFlxxxzDAMDA9xwww381m/9Ftu3bweKbwNHH300V1999WHbf+Mb3+C2227jgQceYMmSJezfvx+AjRs38tnPfpaVK1fywAMP8MEPfpB77rkHKLqR7rvvPhYuXDi3ijcw8CX1nSONjtzJm2/vuusurrzySpaU4/wcf/zxPP/889x3331ceumlh7Z78cUXDz2/9NJLKwl7sEtH/c7ppWppPkZHXrVqFQ899NBhZf/8z//Mnj175jSV4YSDBw9y7LHHHhobf/v27Tz22GOH1lc53LKBr/418b1+927IfPl7vaHf96YaBbmV0ZHPP/98xsfHufHGGwH4+c9/zkc/+lGuuOKKQy326Vx44YV84QtfYLz8+rF//36OOeYYVqxYwS233AIU3UHf+9735l7RIzDw1b+cXqq25mN05Ijgq1/9KrfccgsrV67k9NNPZ/Hixfzpn/7pjN9jzZo1rF27lqGhIVavXs2nP/1poJj96vOf/zxnnXUWb3rTm7jtttvmXtEj/Q4Oj6y+tWBB0bKfLAIOHnxlubrabIdHrsHoyA6PLB3i9FK15ujIr2SXjvqX00tJhzHw1b+Gh2HrVli+vOjGWb68WLbZp5qyS0f9ze/1fSUziYhOV6MrzOX8qy18ST1h8eLF7Nu3b05B128yk3379rF48eJZvc4WvqSesGzZMsbGxti7d2+nq9IVFi9ezLJly2b1GgNfUk941atexYoVKzpdjZ5ml44k1YSBL0k1YeBLUk0Y+JJUEwa+pN7nMNgz4lU6knrbfExv1ads4auzbJmpVQ6DPWO28NU5tsxUhfmY3qpPVdLCj4g1EfF4ROyMiE1TbPPeiHg0Ih6JiP9ZxX7V42yZqQrzMb1Vn2o58CNiIXAd8G5gFbAhIlZN2mYl8EfA2zLzTcB/bHW/6gO2zFQFh8GesSpa+OcCOzPzqcx8CbgZWDdpm38HXJeZPwHIzOcq2K+6zKy7422ZqQoOgz1jVQT+KcCPGpbHyrJGpwOnR8T/jYj7I2JNszeKiI0RMRoRow6Q1FvmNF+4LTNVZXgYdu0qpq7ctcuwn0K7rtI5ClgJnAdsAP4mIo6dvFFmbs3MocwcWrp0aZuqpirMqTvelpnUVlVcpfM0cGrD8rKyrNEY8EBm/gz4+4h4guIPwIMV7F9dYM7d8U5QIrVNFS38B4GVEbEiIhYB64Ftk7b5GkXrnog4kaKL56kK9q0uYXe81P1aDvzMPAB8CLgDeAz4SmY+EhHXRMTacrM7gH0R8SjwTeA/Zea+Vvet7mF3vNT9olunCxsaGsrR0dFOV0OzMDJS9Nnv2VO07LdssbdGareIeCgzh5qt805bVcbueKm7OZaOJNWEgS/VgGPUCQx8qbPakMRzuilOfcnAlzqlTUnsGHWaYOBLndKmJHaMOk0w8KVOaVMSe1OcJhj4Uqe0KYm9KU4TDHzwEgZ1RpuS2DHqNMEbr5xmT50y8flqw+3J3hQncGiFokW/e/cry5cvL8bVlqQecqShFezS8RIGSTVh4HsJg6SaMPC9hEFSTRj4XsIgqSa8Sge8hEFSLdjCl6SaMPAlqSYMfEmqCQNfkmrCwJekmjDwJakmDHxJqgkDX5JqwsCXpJow8CWpJgx8SaoJA1+SasLAl6SaMPAlqSYqCfyIWBMRj0fEzojYdITtfiMiMiKazrcoSZo/LQd+RCwErgPeDawCNkTEqibbvQ74MPBAq/uUJM1eFS38c4GdmflUZr4E3Aysa7LdnwCfBF6oYJ+SpFmqIvBPAX7UsDxWlh0SEb8EnJqZXz/SG0XExogYjYjRvXv3VlA1aeZGRmBwEBYsKB5HRjpdI6la837SNiIWAP8N+Oh022bm1swcysyhpUuXznfVpENGRmDjRti9GzKLx40bDX31lyoC/2ng1IblZWXZhNcBbwbujYhdwFuAbZ64VTfZvBnGxw8vGx8vyqV+UUXgPwisjIgVEbEIWA9sm1iZmT/NzBMzczAzB4H7gbWZOVrBvqVK7Nkzu3KpF7Uc+Jl5APgQcAfwGPCVzHwkIq6JiLWtvr/UDgMDsyuXetFRVbxJZt4O3D6p7GNTbHteFfuUqrRlS9Fn39its2RJUS71C++0lYDhYdi6FZYvh4jicevWolzqF5W08KV+MDxswKu/2cKXpJow8CWpJgx8qRO8rVcdYB++1G4Tt/VOXBI0cVsveBJB88oWvtRu3tarDjHwpXbztl51iIEvtZu39apDDHyp3bZsKW7jbeRtvWoDA19qN2/rVYd4lY7UCd7Wqw6whS9JNWHgS1JNGPiSVBMGviTVhIEvSTVh4EtSTRj4klQTBr4k1YSBL0k1YeBLUk0Y+JJUEwa+JNWEgS9JNWHgS1JNGPiSVBMGviTVhIEvSTVh4EtSTVQS+BGxJiIej4idEbGpyfo/iIhHI+LhiLg7IpZXsV9J0sy1HPgRsRC4Dng3sArYEBGrJm32XWAoM88EbgX+rNX9SpJmp4oW/rnAzsx8KjNfAm4G1jVukJnfzMzxcvF+YFkF+5UkzUIVgX8K8KOG5bGybCrvB75RwX4lSbNwVDt3FhGXAUPAr0yxfiOwEWBgYKCNNZOk/ldFC/9p4NSG5WVl2WEi4gJgM7A2M19s9kaZuTUzhzJzaOnSpRVUTZI0oYrAfxBYGRErImIRsB7Y1rhBRJwN/DVF2D9XwT4lSbPUcuBn5gHgQ8AdwGPAVzLzkYi4JiLWlpt9CjgauCUitkfEtineTpI0Tyq5Dj8zb8/M0zPztMzcUpZ9LDO3lc8vyMyTMnN1+bP2yO/Y/0ZGYHAQFiwoHkdGOl0jSf2urSdtVRgZgY0bYby8UHX37mIZYHi4c/WS1N8cWqEDNm9+OewnjI8X5XPmVwZJ07CF3wF79syufFp+ZZA0A7bwO2CqWwzmfOvBvHxlkNRvDPwO2LIFliw5vGzJkqJ8Tir/yiCpHxn4HTA8DFu3wvLlEFE8bt3aQu9L5V8ZJPUjA79Dhodh1y44eLB4bKmrvfKvDJL6kYHfDyr/yiCpH3mVTr8YHjbgJR2RLXxJqgkDX5JqwsCXpJow8CWpJgx8SaoJA1+SasLAl6SaMPAlqSYMfEmqCQNfkmrCwJekmjDwJakmDHxphpw2WL3O0TKlGXDaYPUDW/jSDDhtsPqBgS/NgNMGz5xdX93LwJ8nfuj7i9MGz8xE19fu3ZD5cteXn//uYODPAz/0/cdpg2fGrq/uZuDPAz/0/cdpg2fGrq/u5lU688APfX9y2uDpDQwU32iblavzbOHPA/t7VVd2fXU3A38e+KFXXdn11d0qCfyIWBMRj0fEzojY1GT9qyPiy+X6ByJisIr9dis/9Kqz4WHYtQsOHiwe/dx3j5b78CNiIXAdcCEwBjwYEdsy89GGzd4P/CQz/3VErAc+Cfxmq/vuZvb3Suo2VbTwzwV2ZuZTmfkScDOwbtI264Abyue3AudHRFSwb0nSDFUR+KcAP2pYHivLmm6TmQeAnwInTH6jiNgYEaMRMbp3794KqiZJmtBVJ20zc2tmDmXm0NKlSztdHUnqK1UE/tPAqQ3Ly8qypttExFHALwD7Kti3JGmGqgj8B4GVEbEiIhYB64Ftk7bZBlxePr8EuCczs4J9S5JmqOWrdDLzQER8CLgDWAhcn5mPRMQ1wGhmbgM+D3wpInYC+yn+KEiS2qiSoRUy83bg9kllH2t4/gJwaRX7kiTNTVedtJUkzR8DX5JqopaB7+QkkuqodsMjOxm1pLqqXQvfyUkk1VXtAt/JSSTVVe0Cv9XJSez/l9Srahf4rUxO4uTkqiMbOf2jdoHfyuQk9v+rbmzk9Jfo1iFthoaGcnR0tNPVOMyCBcWHfrKIYnYfqd8MDjaflHz58mI2K3WfiHgoM4earatdC78VTk6uuvEih/5i4M+Ck5OrozrQmW4jp78Y+LPg5OTqmA51ptvI6S/24Uu9oIOd6SMjxYUJe/YULfstW2zkdLMj9eEb+FIv8IoBzZAnbaVeZ2e6KmDgS73AznRVwMCvE2+Z7F1eMaAK1G545NpyXOjeNzzsv5VaYgu/LhwXQqo9A78uvGVSqj0Dvy6OP3525ZL6joEvSTVh4NfF/v2zK5fUdwz8uvDGHan2DPy68MYdqfYM/Lrwxh2p9rzxqk68cUeqNVv4klQTBr4k1URLgR8Rx0fEnRGxo3w8rsk2qyPiOxHxSEQ8HBG/2co+JUlz02oLfxNwd2auBO4ulycbB347M98ErAE+ExHHtrjf+nLES0lz1GrgrwNuKJ/fAFw8eYPMfCIzd5TP/wF4Dlja4n7rqUPzmkrqD60G/kmZ+Uz5/FngpCNtHBHnAouAJ6dYvzEiRiNidO/evS1WrQ854qWkFkx7WWZE3AW8vsmqw1ImMzMippwgNyJOBr4EXJ6ZTSfhzMytwFYo5rSdrm6144iXklowbeBn5gVTrYuIH0fEyZn5TBnoz02x3THA14HNmXn/nGtbdwMDRTdOs3JJmkarXTrbgMvL55cDt03eICIWAV8FbszMW1vcX705PII8aa8WtBr4nwAujIgdwAXlMhExFBGfK7d5L/AO4IqI2F7+rG5xv/Xk8Aj15kl7tSgyu7OrfGhoKEdHRztdjZ4xMlKcu92zp+jh2bLFvwN9Z3CweZfe8uWwa1e7a6MuFREPZeZQs3WOpdMHnJ+8JjxprxY5tEIf8GrNmnBOA7XIwO8DNvxqwpP2apGB3wds+NWEJ+3VIgO/D9jwq5Hh4eIE7cGDxaNhr1kw8PuADT9JM+FVOn3CyawkTccWviTVhIEvSTVh4EtSTRj4klQTBr4k1YSBL0k1YeBLUk30X+A7QYSkHjXf8dVfN145TrCkHtWO+OqvCVCcIEJSj6oqvo40AUp/dek4TrCkHtWO+OqvwHecYEk9qh3x1V+B7zjBknpUO+KrvwLfcYIl9ah2xFd/nbStg5GRYrLaPXuK73pbtvgHTdIhRzpp21+XZfY7LzuV1IL+6tLpd5s3vxz2E8bHi3JJmoaB30u87FRSCwz8XuJlp5JaYOD3Ei87ldQCA7+XeNmppBZ4lU6vGR424CXNiS18SaqJlgI/Io6PiDsjYkf5eNwRtj0mIsYi4i9a2ackaW5abeFvAu7OzJXA3eXyVP4E+LsW9ydJmqNWA38dcEP5/Abg4mYbRcQ5wEnA37a4P0md4mxyPa/VwD8pM58pnz9LEeqHiYgFwJ8DV7e4L/UDQ6M3TQzrsXs3ZL48rIf/fj1l2qt0IuIu4PVNVh12P39mZkQ0G4ntg8DtmTkWEdPtayOwEWDAm4n6j2MB9a4jDevhv13PaGm0zIh4HDgvM5+JiJOBezPz30zaZgR4O3AQOBpYBPxlZh6pv9/RMvuRU1D2rgULipb9ZBFw8GD766MpzecUh9uAy8vnlwO3Td4gM4czcyAzBym6dW6cLuzVpxwLqHc5rEdfaDXwPwFcGBE7gAvKZSJiKCI+12rl1GcMjd41i2E9PE3TvVoK/Mzcl5nnZ+bKzLwgM/eX5aOZ+TtNtv9iZn6olX2qhzkWUO+a4bAentvtbs54pfZyxq6+5mmazjtSH76BL6kyntvtvPk8aStJh3iaprsZ+JIq42ma7mbgS6qMUzZ0N8fDl1Qpp2zoXrbwJakmDHxJqgkDX5JqwsCXpJow8CWpJgx8SaoJA1+SasLAl6SaMPAlqSYMfEmqCQNfkmrCwJekmjDwJakmDHxJqgkDX5JqwsCXpJow8CWpJgx8SaoJA19SzxoZgcFBWLCgeBwZ6XSNuptz2krqSSMjsHEjjI8Xy7t3F8vgnLpTsYUvqSdt3vxy2E8YHy/K1ZyBL6kn7dkzu3IZ+JJ61MDA7Mpl4EvqUVu2wJIlh5ctWVKUqzkDX1JPGh6GrVth+XKIKB63bvWE7ZG0dJVORBwPfBkYBHYB783MnzTZbgD4HHAqkMBFmbmrlX1L0vCwAT8brbbwNwF3Z+ZK4O5yuZkbgU9l5huBc4HnWtyvJGmWWg38dcAN5fMbgIsnbxARq4CjMvNOgMx8PjPHJ28nSZpfrQb+SZn5TPn8WeCkJtucDvxTRPzviPhuRHwqIhY2e7OI2BgRoxExunfv3harJklqNG0ffkTcBby+yarDbm/IzIyInGIfbwfOBvZQ9PlfAXx+8oaZuRXYCjA0NNTsvSRJczRt4GfmBVOti4gfR8TJmflMRJxM8775MWB7Zj5VvuZrwFtoEviSpPnTapfONuDy8vnlwG1NtnkQODYilpbL7wIebXG/kqRZajXwPwFcGBE7gAvKZSJiKCI+B5CZPweuBu6OiO8DAfxNi/uVJM1SS4Gfmfsy8/zMXJmZF2Tm/rJ8NDN/p2G7OzPzzMw8IzOvyMyXWq24KuQYs1ItODxy3TnGrFQbDq1Qd44xK9WGgd9hHe9NcYxZqTYM/A6a6E3ZvRsyX+5NaWvoO8asVBsGfgd1RW+KY8xKtWHgd1BX9KY4xqxUG16l00EDA0U3TrPytnKMWakWbOF3kL0pktrJwO8ge1MktZNdOh1mb4qkdrGFL0k1YeBLUk0Y+JJUEwa+JNWEgS9JNWHgS+qojg8gWCNelimpY5yOob1s4UvqmK4YQLBGDHxJHdMVAwjWiIEvqWOcjqG9DHxJHeMAgu1l4EvqGAcQbC+v0pHUUQ4g2D628CWpJgx8SaoJA1+SasLAl6SaMPAlqSYMfEmqCQNfkmrCwJekmjDwJakmDHxJqonIzE7XoamI2AvsnsGmJwL/OM/VqVqv1bnX6gvWuV16rc69Vl+YfZ2XZ+bSZiu6NvBnKiJGM3Oo0/WYjV6rc6/VF6xzu/RanXutvlBtne3SkaSaMPAlqSb6IfC3droCc9Brde61+oJ1bpdeq3Ov1RcqrHPP9+FLkmamH1r4kqQZ6InAj4jjI+LOiNhRPh7XZJt3RsT2hp8XIuLict0XI+LvG9at7oY6l9v9vKFe2xrKV0TEAxGxMyK+HBGLOl3fiFgdEd+JiEci4uGI+M2GdW07xhGxJiIeL4/NpibrX10es53lMRxsWPdHZfnjEfFr81XHWdb3DyLi0fKY3h0RyxvWNf18dEGdr4iIvQ11+52GdZeXn6MdEXF5F9X52ob6PhER/9Swru3HOSKuj4jnIuIHU6yPiPjv5e/zcET8UsO6uR3jzOz6H+DPgE3l803AJ6fZ/nhgP7CkXP4icEk31hl4foryrwDry+efBX630/UFTgdWls//FfAMcGw7jzGwEHgSeAOwCPgesGrSNh8EPls+Xw98uXy+qtz+1cCK8n0WdkF939nwWf3difoe6fPRBXW+AviLJq89HniqfDyufH5cN9R50va/B1zf4eP8DuCXgB9Msf4i4BtAAG8BHmj1GPdECx9YB9xQPr8BuHia7S8BvpGZ4/NaqyObbZ0PiYgA3gXcOpfXz9G09c3MJzJzR/n8H4DngKY3eMyjc4GdmflUZr4E3ExR90aNv8utwPnlMV0H3JyZL2bm3wM7y/fraH0z85sNn9X7gWXzXKfpzOQYT+XXgDszc39m/gS4E1gzT/VsNNs6bwBuakO9ppSZf0fRMJ3KOuDGLNwPHBsRJ9PCMe6VwD8pM58pnz8LnDTN9ut55T/mlvJr0bUR8erKa/hKM63z4ogYjYj7J7qggBOAf8rMA+XyGHDKPNYVZnmMI+JcipbUkw3F7TjGpwA/alhudmwObVMew59SHNOZvLZqs93n+yladROafT7m20zr/Bvlv/etEXHqLF9btRnvt+wyWwHc01DcieM8nal+pzkf46Mqq1qLIuIu4PVNVm1uXMjMjIgpLy0q/wKeAdzRUPxHFCG2iOISp/8MXNMldV6emU9HxBuAeyLi+xQBVbmKj/GXgMsz82BZPC/HuE4i4jJgCPiVhuJXfD4y88nm79BW/we4KTNfjIh/T/GN6l0drtNMrQduzcyfN5R163GuVNcEfmZeMNW6iPhxRJycmc+UYfPcEd7qvcBXM/NnDe890XJ9MSK+AFzdLXXOzKfLx6ci4l7gbOB/UXx9O6psoS4Dnu6G+kbEMcDXgc3l18yJ956XY9zE08CpDcvNjs3ENmMRcRTwC8C+Gb62ajPaZ0RcQPGH91cy88WJ8ik+H/MdRNPWOTP3NSx+juIc0MRrz5v02nsrr+Erzebfdj3wHxoLOnScpzPV7zTnY9wrXTrbgIkz0ZcDtx1h21f0zZUBNtE3fjHQ9Kx4xaatc0QcN9H1EREnAm8DHs3izMw3Kc5FTPn6DtR3EfBVin7FWyeta9cxfhBYGcVVTIso/vNOvqqi8Xe5BLinPKbbgPVRXMWzAlgJ/L95queM6xsRZwN/DazNzOcaypt+Pua5vjOt88kNi2uBx8rndwC/Wtb9OOBXOfzbdsfqDBARv0hxovM7DWWdOs7T2Qb8dnm1zluAn5YNq7kf43afmZ7LD0X/693ADuAu4PiyfAj4XMN2gxR//RZMev09wPcpQuh/AEd3Q52Bt5b1+l75+P6G17+BIox2ArcAr+6C+l4G/AzY3vCzut3HmOLqhScoWmCby7JrKAITYHF5zHaWx/ANDa/dXL7uceDdbfr8Tlffu4AfNxzTbdN9Prqgzv8VeKSs2zeBX2x47VXlsd8JXNktdS6XPw58YtLrOnKcKRqmz5T/p8Yozt98APhAuT6A68rf5/vAUKvH2DttJakmeqVLR5LUIgNfkmrCwJekmjDwJakmDHxJqgkDX5JqwsCXpJow8CWpJv4/65435zGTMUwAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQIyuEz9ANb2"
      },
      "source": [
        "## Question 7: Training the embedding! What is the best performance you can get? Please report both the best loss and accuracy on Gradescope. (20 Points)\n",
        "\n",
        "We want to optimize our embeddings for the task of **classifying edges as positive or negative**. Given an edge and the embeddings for each node, the dot product of the embeddings, followed by a sigmoid, should give us the likelihood of that edge being either positive (output of sigmoid > 0.5) or negative (output of sigmoid < 0.5).\n",
        "\n",
        "Note that we're using the functions you wrote in the previous questions, _as well as the variables initialized in previous cells_. If you're running into issues, make sure your answers to questions 1-6 are correct.\n",
        "\n",
        "### **Explanation in Detail**\n",
        "> To predict whether an edge exists or not, **dot product** is used as **similarity measure** to estimate the similarity between two nodes of an edge. Then, activation function, `sigmoid`, is applied to project the output values to range $(0, 1)$. Finally, loss and accuracy are computed by criterion `BCELoss` and evaluation metrics `accuracy`, respectively. <br> To implement evaluation metrics `accuracy`, I first map predicting values to either 0 or 1 using `torch.where` with the condition determining whether the value is greater than 0.5 or not. Then, I perform sample-wise **XNOR** and sum them up to obtain the total number of **true positive's** and **true negative's**. Finally, we get accuracy which can be written down as follows: $$\\frac{\\#True\\ positive's\\ +\\ \\#True\\ negative's}{\\#Training\\ edges\\ (samples)}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDeQTNNxqH0j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7e84018-a1a3-4534-897a-7f28a0dd2eef"
      },
      "source": [
        "from torch.optim import SGD\n",
        "import torch.nn as nn\n",
        "\n",
        "def accuracy(pred, label):\n",
        "  # TODO: Implement the accuracy function. This function takes the \n",
        "  # pred tensor (the resulting tensor after sigmoid) and the label \n",
        "  # tensor (torch.LongTensor). Predicted value greater than 0.5 will \n",
        "  # be classified as label 1. Else it will be classified as label 0.\n",
        "  # The returned accuracy should be rounded to 4 decimal places. \n",
        "  # For example, accuracy 0.82956 will be rounded to 0.8296.\n",
        "\n",
        "  accu = 0.0\n",
        "\n",
        "  ############# Your code here ############\n",
        "  n_train_edges = len(label)\n",
        "  pred = torch.where(pred > 0.5, 1, 0)\n",
        "  with torch.no_grad():\n",
        "    tp_tn = torch.sum(torch.logical_not(torch.logical_xor(pred, label)))\n",
        "  accu = round((tp_tn / n_train_edges).item(), 4)\n",
        "  #########################################\n",
        "\n",
        "  return accu\n",
        "\n",
        "def train(emb, loss_fn, sigmoid, train_label, train_edge):\n",
        "  # TODO: Train the embedding layer here. You can also change epochs and \n",
        "  # learning rate. In general, you need to implement: \n",
        "  # (1) Get the embeddings of the nodes in train_edge\n",
        "  # (2) Dot product the embeddings between each node pair\n",
        "  # (3) Feed the dot product result into sigmoid\n",
        "  # (4) Feed the sigmoid output into the loss_fn\n",
        "  # (5) Print both loss and accuracy of each epoch \n",
        "  # (6) Update the embeddings using the loss and optimizer \n",
        "  # (as a sanity check, the loss should decrease during training)\n",
        "\n",
        "  epochs = 500\n",
        "  learning_rate = 0.1\n",
        "\n",
        "  optimizer = SGD(emb.parameters(), lr=learning_rate, momentum=0.9)\n",
        "\n",
        "  for i in range(epochs):\n",
        "\n",
        "    ############# Your code here ############\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # (1) Get node embeddings of all train_edges\n",
        "    embs_src = emb(train_edge[0, :])\n",
        "    embs_dst = emb(train_edge[1, :])\n",
        "\n",
        "    # (2) Compute similarity using dot product\n",
        "    # Perform Hadamard product then sum\n",
        "    embs_sim = torch.sum(embs_src * embs_dst, dim=1)\n",
        "\n",
        "    # (3) Apply activation function, sigmoid\n",
        "    pred = sigmoid(embs_sim)\n",
        "\n",
        "    # (4) Compute loss and do gradient descent\n",
        "    loss = loss_fn(pred, train_label)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    acc = accuracy(pred, train_label)\n",
        "    print(f\"Epoch{i} | Loss {loss} | Accuracy {acc}\")\n",
        "    #########################################\n",
        "\n",
        "loss_fn = nn.BCELoss()   # Loss criterion\n",
        "sigmoid = nn.Sigmoid()   # Output activatin \n",
        "\n",
        "print(pos_edge_index.shape)\n",
        "\n",
        "# Generate the positive and negative labels\n",
        "pos_label = torch.ones(pos_edge_index.shape[1], )\n",
        "neg_label = torch.zeros(neg_edge_index.shape[1], )\n",
        "print(f\"#Samples {len(pos_label)+len(neg_label)} | #Positive edges {len(pos_label)} | # Negative edges {len(neg_label)}\")\n",
        "\n",
        "# Concat positive and negative labels into one tensor\n",
        "train_label = torch.cat([pos_label, neg_label], dim=0)\n",
        "\n",
        "# Concat positive and negative edges into one tensor\n",
        "# Since the network is very small, we do not split the edges into val/test sets\n",
        "train_edge = torch.cat([pos_edge_index, neg_edge_index], dim=1)\n",
        "print(train_edge.shape)\n",
        "\n",
        "train(emb, loss_fn, sigmoid, train_label, train_edge)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 78])\n",
            "#Samples 156 | #Positive edges 78 | # Negative edges 78\n",
            "torch.Size([2, 156])\n",
            "Epoch0 | Loss 1.9490337371826172 | Accuracy 0.5\n",
            "Epoch1 | Loss 1.9358919858932495 | Accuracy 0.5\n",
            "Epoch2 | Loss 1.9111214876174927 | Accuracy 0.5\n",
            "Epoch3 | Loss 1.8762487173080444 | Accuracy 0.5\n",
            "Epoch4 | Loss 1.8327783346176147 | Accuracy 0.5\n",
            "Epoch5 | Loss 1.7821706533432007 | Accuracy 0.5\n",
            "Epoch6 | Loss 1.7258175611495972 | Accuracy 0.5\n",
            "Epoch7 | Loss 1.6650363206863403 | Accuracy 0.5\n",
            "Epoch8 | Loss 1.601055383682251 | Accuracy 0.5\n",
            "Epoch9 | Loss 1.5350077152252197 | Accuracy 0.5\n",
            "Epoch10 | Loss 1.4679254293441772 | Accuracy 0.5\n",
            "Epoch11 | Loss 1.400735855102539 | Accuracy 0.5\n",
            "Epoch12 | Loss 1.3342571258544922 | Accuracy 0.5\n",
            "Epoch13 | Loss 1.2691980600357056 | Accuracy 0.5\n",
            "Epoch14 | Loss 1.2061551809310913 | Accuracy 0.5\n",
            "Epoch15 | Loss 1.1456152200698853 | Accuracy 0.5\n",
            "Epoch16 | Loss 1.0879567861557007 | Accuracy 0.5\n",
            "Epoch17 | Loss 1.0334560871124268 | Accuracy 0.5\n",
            "Epoch18 | Loss 0.9822938442230225 | Accuracy 0.5064\n",
            "Epoch19 | Loss 0.934564471244812 | Accuracy 0.5064\n",
            "Epoch20 | Loss 0.8902869820594788 | Accuracy 0.5064\n",
            "Epoch21 | Loss 0.8494164943695068 | Accuracy 0.5064\n",
            "Epoch22 | Loss 0.8118565082550049 | Accuracy 0.5064\n",
            "Epoch23 | Loss 0.7774702906608582 | Accuracy 0.5128\n",
            "Epoch24 | Loss 0.7460917830467224 | Accuracy 0.5449\n",
            "Epoch25 | Loss 0.7175354957580566 | Accuracy 0.5513\n",
            "Epoch26 | Loss 0.6916043162345886 | Accuracy 0.5641\n",
            "Epoch27 | Loss 0.6680967807769775 | Accuracy 0.5769\n",
            "Epoch28 | Loss 0.6468123197555542 | Accuracy 0.6026\n",
            "Epoch29 | Loss 0.6275548934936523 | Accuracy 0.6218\n",
            "Epoch30 | Loss 0.6101365685462952 | Accuracy 0.6218\n",
            "Epoch31 | Loss 0.5943800210952759 | Accuracy 0.6474\n",
            "Epoch32 | Loss 0.5801184177398682 | Accuracy 0.6795\n",
            "Epoch33 | Loss 0.5671975016593933 | Accuracy 0.6859\n",
            "Epoch34 | Loss 0.5554749965667725 | Accuracy 0.7051\n",
            "Epoch35 | Loss 0.5448206663131714 | Accuracy 0.7115\n",
            "Epoch36 | Loss 0.5351164937019348 | Accuracy 0.7115\n",
            "Epoch37 | Loss 0.5262550711631775 | Accuracy 0.7179\n",
            "Epoch38 | Loss 0.5181400179862976 | Accuracy 0.7244\n",
            "Epoch39 | Loss 0.5106843709945679 | Accuracy 0.7308\n",
            "Epoch40 | Loss 0.5038105249404907 | Accuracy 0.7436\n",
            "Epoch41 | Loss 0.49744898080825806 | Accuracy 0.7436\n",
            "Epoch42 | Loss 0.49153801798820496 | Accuracy 0.75\n",
            "Epoch43 | Loss 0.4860226511955261 | Accuracy 0.7692\n",
            "Epoch44 | Loss 0.4808542728424072 | Accuracy 0.7885\n",
            "Epoch45 | Loss 0.47598960995674133 | Accuracy 0.7885\n",
            "Epoch46 | Loss 0.4713906943798065 | Accuracy 0.7949\n",
            "Epoch47 | Loss 0.46702393889427185 | Accuracy 0.8077\n",
            "Epoch48 | Loss 0.4628598690032959 | Accuracy 0.8077\n",
            "Epoch49 | Loss 0.45887237787246704 | Accuracy 0.8077\n",
            "Epoch50 | Loss 0.45503881573677063 | Accuracy 0.8141\n",
            "Epoch51 | Loss 0.45133909583091736 | Accuracy 0.8269\n",
            "Epoch52 | Loss 0.4477558732032776 | Accuracy 0.8333\n",
            "Epoch53 | Loss 0.44427382946014404 | Accuracy 0.8333\n",
            "Epoch54 | Loss 0.440879762172699 | Accuracy 0.8397\n",
            "Epoch55 | Loss 0.43756210803985596 | Accuracy 0.8397\n",
            "Epoch56 | Loss 0.4343109130859375 | Accuracy 0.8397\n",
            "Epoch57 | Loss 0.4311172366142273 | Accuracy 0.8526\n",
            "Epoch58 | Loss 0.42797377705574036 | Accuracy 0.859\n",
            "Epoch59 | Loss 0.42487382888793945 | Accuracy 0.8654\n",
            "Epoch60 | Loss 0.42181190848350525 | Accuracy 0.8654\n",
            "Epoch61 | Loss 0.41878318786621094 | Accuracy 0.8654\n",
            "Epoch62 | Loss 0.41578346490859985 | Accuracy 0.8654\n",
            "Epoch63 | Loss 0.4128090739250183 | Accuracy 0.8718\n",
            "Epoch64 | Loss 0.4098571538925171 | Accuracy 0.8782\n",
            "Epoch65 | Loss 0.4069249927997589 | Accuracy 0.8782\n",
            "Epoch66 | Loss 0.4040103554725647 | Accuracy 0.8782\n",
            "Epoch67 | Loss 0.4011114239692688 | Accuracy 0.8782\n",
            "Epoch68 | Loss 0.3982265293598175 | Accuracy 0.8782\n",
            "Epoch69 | Loss 0.39535436034202576 | Accuracy 0.8782\n",
            "Epoch70 | Loss 0.39249375462532043 | Accuracy 0.8782\n",
            "Epoch71 | Loss 0.38964372873306274 | Accuracy 0.8846\n",
            "Epoch72 | Loss 0.3868034780025482 | Accuracy 0.891\n",
            "Epoch73 | Loss 0.3839723765850067 | Accuracy 0.8974\n",
            "Epoch74 | Loss 0.3811498284339905 | Accuracy 0.9038\n",
            "Epoch75 | Loss 0.3783353269100189 | Accuracy 0.9038\n",
            "Epoch76 | Loss 0.3755285143852234 | Accuracy 0.9038\n",
            "Epoch77 | Loss 0.37272909283638 | Accuracy 0.9038\n",
            "Epoch78 | Loss 0.36993682384490967 | Accuracy 0.9103\n",
            "Epoch79 | Loss 0.3671514689922333 | Accuracy 0.9167\n",
            "Epoch80 | Loss 0.3643729090690613 | Accuracy 0.9167\n",
            "Epoch81 | Loss 0.36160096526145935 | Accuracy 0.9167\n",
            "Epoch82 | Loss 0.3588356375694275 | Accuracy 0.9167\n",
            "Epoch83 | Loss 0.35607680678367615 | Accuracy 0.9167\n",
            "Epoch84 | Loss 0.35332444310188293 | Accuracy 0.9231\n",
            "Epoch85 | Loss 0.35057854652404785 | Accuracy 0.9231\n",
            "Epoch86 | Loss 0.3478390872478485 | Accuracy 0.9295\n",
            "Epoch87 | Loss 0.3451061546802521 | Accuracy 0.9359\n",
            "Epoch88 | Loss 0.34237974882125854 | Accuracy 0.9487\n",
            "Epoch89 | Loss 0.3396598994731903 | Accuracy 0.9487\n",
            "Epoch90 | Loss 0.3369466960430145 | Accuracy 0.9487\n",
            "Epoch91 | Loss 0.33424025774002075 | Accuracy 0.9487\n",
            "Epoch92 | Loss 0.331540584564209 | Accuracy 0.9487\n",
            "Epoch93 | Loss 0.32884785532951355 | Accuracy 0.9487\n",
            "Epoch94 | Loss 0.3261621594429016 | Accuracy 0.9551\n",
            "Epoch95 | Loss 0.3234836161136627 | Accuracy 0.9551\n",
            "Epoch96 | Loss 0.3208123743534088 | Accuracy 0.9551\n",
            "Epoch97 | Loss 0.31814852356910706 | Accuracy 0.9615\n",
            "Epoch98 | Loss 0.3154922425746918 | Accuracy 0.9615\n",
            "Epoch99 | Loss 0.3128436803817749 | Accuracy 0.9615\n",
            "Epoch100 | Loss 0.3102029860019684 | Accuracy 0.9615\n",
            "Epoch101 | Loss 0.3075703978538513 | Accuracy 0.9615\n",
            "Epoch102 | Loss 0.30494603514671326 | Accuracy 0.9615\n",
            "Epoch103 | Loss 0.3023300766944885 | Accuracy 0.9615\n",
            "Epoch104 | Loss 0.2997227609157562 | Accuracy 0.9615\n",
            "Epoch105 | Loss 0.29712429642677307 | Accuracy 0.9615\n",
            "Epoch106 | Loss 0.294534832239151 | Accuracy 0.9615\n",
            "Epoch107 | Loss 0.29195457696914673 | Accuracy 0.9679\n",
            "Epoch108 | Loss 0.2893838584423065 | Accuracy 0.9679\n",
            "Epoch109 | Loss 0.2868227958679199 | Accuracy 0.9679\n",
            "Epoch110 | Loss 0.2842716872692108 | Accuracy 0.9679\n",
            "Epoch111 | Loss 0.2817307114601135 | Accuracy 0.9679\n",
            "Epoch112 | Loss 0.27920007705688477 | Accuracy 0.9679\n",
            "Epoch113 | Loss 0.2766801416873932 | Accuracy 0.9679\n",
            "Epoch114 | Loss 0.2741710841655731 | Accuracy 0.9744\n",
            "Epoch115 | Loss 0.27167317271232605 | Accuracy 0.9744\n",
            "Epoch116 | Loss 0.2691866457462311 | Accuracy 0.9744\n",
            "Epoch117 | Loss 0.2667117118835449 | Accuracy 0.9744\n",
            "Epoch118 | Loss 0.26424872875213623 | Accuracy 0.9808\n",
            "Epoch119 | Loss 0.26179787516593933 | Accuracy 0.9808\n",
            "Epoch120 | Loss 0.2593594193458557 | Accuracy 0.9808\n",
            "Epoch121 | Loss 0.25693368911743164 | Accuracy 0.9808\n",
            "Epoch122 | Loss 0.25452086329460144 | Accuracy 0.9872\n",
            "Epoch123 | Loss 0.2521212100982666 | Accuracy 0.9872\n",
            "Epoch124 | Loss 0.2497349977493286 | Accuracy 0.9872\n",
            "Epoch125 | Loss 0.24736252427101135 | Accuracy 0.9872\n",
            "Epoch126 | Loss 0.24500399827957153 | Accuracy 0.9872\n",
            "Epoch127 | Loss 0.24265964329242706 | Accuracy 0.9872\n",
            "Epoch128 | Loss 0.240329772233963 | Accuracy 0.9936\n",
            "Epoch129 | Loss 0.2380145639181137 | Accuracy 0.9936\n",
            "Epoch130 | Loss 0.23571433126926422 | Accuracy 0.9936\n",
            "Epoch131 | Loss 0.23342925310134888 | Accuracy 0.9936\n",
            "Epoch132 | Loss 0.23115955293178558 | Accuracy 0.9936\n",
            "Epoch133 | Loss 0.22890548408031464 | Accuracy 0.9936\n",
            "Epoch134 | Loss 0.22666729986667633 | Accuracy 0.9936\n",
            "Epoch135 | Loss 0.2244451493024826 | Accuracy 0.9936\n",
            "Epoch136 | Loss 0.22223927080631256 | Accuracy 0.9936\n",
            "Epoch137 | Loss 0.2200498878955841 | Accuracy 0.9936\n",
            "Epoch138 | Loss 0.21787714958190918 | Accuracy 0.9936\n",
            "Epoch139 | Loss 0.2157212793827057 | Accuracy 0.9936\n",
            "Epoch140 | Loss 0.21358245611190796 | Accuracy 1.0\n",
            "Epoch141 | Loss 0.21146076917648315 | Accuracy 1.0\n",
            "Epoch142 | Loss 0.20935650169849396 | Accuracy 1.0\n",
            "Epoch143 | Loss 0.20726974308490753 | Accuracy 1.0\n",
            "Epoch144 | Loss 0.20520064234733582 | Accuracy 1.0\n",
            "Epoch145 | Loss 0.20314936339855194 | Accuracy 1.0\n",
            "Epoch146 | Loss 0.20111599564552307 | Accuracy 1.0\n",
            "Epoch147 | Loss 0.19910065829753876 | Accuracy 1.0\n",
            "Epoch148 | Loss 0.19710348546504974 | Accuracy 1.0\n",
            "Epoch149 | Loss 0.1951245367527008 | Accuracy 1.0\n",
            "Epoch150 | Loss 0.1931639462709427 | Accuracy 1.0\n",
            "Epoch151 | Loss 0.19122175872325897 | Accuracy 1.0\n",
            "Epoch152 | Loss 0.18929804861545563 | Accuracy 1.0\n",
            "Epoch153 | Loss 0.18739290535449982 | Accuracy 1.0\n",
            "Epoch154 | Loss 0.18550635874271393 | Accuracy 1.0\n",
            "Epoch155 | Loss 0.18363840878009796 | Accuracy 1.0\n",
            "Epoch156 | Loss 0.1817891001701355 | Accuracy 1.0\n",
            "Epoch157 | Loss 0.1799585074186325 | Accuracy 1.0\n",
            "Epoch158 | Loss 0.1781465858221054 | Accuracy 1.0\n",
            "Epoch159 | Loss 0.1763533502817154 | Accuracy 1.0\n",
            "Epoch160 | Loss 0.17457880079746246 | Accuracy 1.0\n",
            "Epoch161 | Loss 0.17282292246818542 | Accuracy 1.0\n",
            "Epoch162 | Loss 0.1710856705904007 | Accuracy 1.0\n",
            "Epoch163 | Loss 0.1693670004606247 | Accuracy 1.0\n",
            "Epoch164 | Loss 0.16766688227653503 | Accuracy 1.0\n",
            "Epoch165 | Loss 0.16598530113697052 | Accuracy 1.0\n",
            "Epoch166 | Loss 0.1643221378326416 | Accuracy 1.0\n",
            "Epoch167 | Loss 0.16267737746238708 | Accuracy 1.0\n",
            "Epoch168 | Loss 0.16105090081691742 | Accuracy 1.0\n",
            "Epoch169 | Loss 0.15944263339042664 | Accuracy 1.0\n",
            "Epoch170 | Loss 0.15785254538059235 | Accuracy 1.0\n",
            "Epoch171 | Loss 0.15628041326999664 | Accuracy 1.0\n",
            "Epoch172 | Loss 0.1547262817621231 | Accuracy 1.0\n",
            "Epoch173 | Loss 0.15318994224071503 | Accuracy 1.0\n",
            "Epoch174 | Loss 0.15167135000228882 | Accuracy 1.0\n",
            "Epoch175 | Loss 0.15017032623291016 | Accuracy 1.0\n",
            "Epoch176 | Loss 0.14868679642677307 | Accuracy 1.0\n",
            "Epoch177 | Loss 0.14722061157226562 | Accuracy 1.0\n",
            "Epoch178 | Loss 0.14577162265777588 | Accuracy 1.0\n",
            "Epoch179 | Loss 0.14433974027633667 | Accuracy 1.0\n",
            "Epoch180 | Loss 0.14292477071285248 | Accuracy 1.0\n",
            "Epoch181 | Loss 0.14152660965919495 | Accuracy 1.0\n",
            "Epoch182 | Loss 0.14014510810375214 | Accuracy 1.0\n",
            "Epoch183 | Loss 0.13878008723258972 | Accuracy 1.0\n",
            "Epoch184 | Loss 0.13743141293525696 | Accuracy 1.0\n",
            "Epoch185 | Loss 0.1360989362001419 | Accuracy 1.0\n",
            "Epoch186 | Loss 0.13478250801563263 | Accuracy 1.0\n",
            "Epoch187 | Loss 0.1334819495677948 | Accuracy 1.0\n",
            "Epoch188 | Loss 0.13219709694385529 | Accuracy 1.0\n",
            "Epoch189 | Loss 0.13092781603336334 | Accuracy 1.0\n",
            "Epoch190 | Loss 0.12967394292354584 | Accuracy 1.0\n",
            "Epoch191 | Loss 0.12843528389930725 | Accuracy 1.0\n",
            "Epoch192 | Loss 0.12721168994903564 | Accuracy 1.0\n",
            "Epoch193 | Loss 0.12600301206111908 | Accuracy 1.0\n",
            "Epoch194 | Loss 0.12480904161930084 | Accuracy 1.0\n",
            "Epoch195 | Loss 0.12362965196371078 | Accuracy 1.0\n",
            "Epoch196 | Loss 0.12246467918157578 | Accuracy 1.0\n",
            "Epoch197 | Loss 0.12131396681070328 | Accuracy 1.0\n",
            "Epoch198 | Loss 0.1201772689819336 | Accuracy 1.0\n",
            "Epoch199 | Loss 0.11905450373888016 | Accuracy 1.0\n",
            "Epoch200 | Loss 0.11794549971818924 | Accuracy 1.0\n",
            "Epoch201 | Loss 0.11685004830360413 | Accuracy 1.0\n",
            "Epoch202 | Loss 0.11576800793409348 | Accuracy 1.0\n",
            "Epoch203 | Loss 0.11469921469688416 | Accuracy 1.0\n",
            "Epoch204 | Loss 0.11364353448152542 | Accuracy 1.0\n",
            "Epoch205 | Loss 0.11260075122117996 | Accuracy 1.0\n",
            "Epoch206 | Loss 0.11157075315713882 | Accuracy 1.0\n",
            "Epoch207 | Loss 0.11055333912372589 | Accuracy 1.0\n",
            "Epoch208 | Loss 0.10954839736223221 | Accuracy 1.0\n",
            "Epoch209 | Loss 0.10855571925640106 | Accuracy 1.0\n",
            "Epoch210 | Loss 0.1075751930475235 | Accuracy 1.0\n",
            "Epoch211 | Loss 0.10660665482282639 | Accuracy 1.0\n",
            "Epoch212 | Loss 0.1056499108672142 | Accuracy 1.0\n",
            "Epoch213 | Loss 0.1047048568725586 | Accuracy 1.0\n",
            "Epoch214 | Loss 0.10377130657434464 | Accuracy 1.0\n",
            "Epoch215 | Loss 0.10284915566444397 | Accuracy 1.0\n",
            "Epoch216 | Loss 0.10193821787834167 | Accuracy 1.0\n",
            "Epoch217 | Loss 0.1010383665561676 | Accuracy 1.0\n",
            "Epoch218 | Loss 0.10014943778514862 | Accuracy 1.0\n",
            "Epoch219 | Loss 0.09927129745483398 | Accuracy 1.0\n",
            "Epoch220 | Loss 0.09840380400419235 | Accuracy 1.0\n",
            "Epoch221 | Loss 0.09754682332277298 | Accuracy 1.0\n",
            "Epoch222 | Loss 0.09670020639896393 | Accuracy 1.0\n",
            "Epoch223 | Loss 0.09586381912231445 | Accuracy 1.0\n",
            "Epoch224 | Loss 0.09503752738237381 | Accuracy 1.0\n",
            "Epoch225 | Loss 0.09422118961811066 | Accuracy 1.0\n",
            "Epoch226 | Loss 0.09341468662023544 | Accuracy 1.0\n",
            "Epoch227 | Loss 0.09261786937713623 | Accuracy 1.0\n",
            "Epoch228 | Loss 0.09183063358068466 | Accuracy 1.0\n",
            "Epoch229 | Loss 0.0910528227686882 | Accuracy 1.0\n",
            "Epoch230 | Loss 0.0902843326330185 | Accuracy 1.0\n",
            "Epoch231 | Loss 0.08952503651380539 | Accuracy 1.0\n",
            "Epoch232 | Loss 0.08877479285001755 | Accuracy 1.0\n",
            "Epoch233 | Loss 0.08803348243236542 | Accuracy 1.0\n",
            "Epoch234 | Loss 0.08730100840330124 | Accuracy 1.0\n",
            "Epoch235 | Loss 0.08657722920179367 | Accuracy 1.0\n",
            "Epoch236 | Loss 0.08586204051971436 | Accuracy 1.0\n",
            "Epoch237 | Loss 0.08515532314777374 | Accuracy 1.0\n",
            "Epoch238 | Loss 0.08445695787668228 | Accuracy 1.0\n",
            "Epoch239 | Loss 0.08376681804656982 | Accuracy 1.0\n",
            "Epoch240 | Loss 0.0830848291516304 | Accuracy 1.0\n",
            "Epoch241 | Loss 0.08241084963083267 | Accuracy 1.0\n",
            "Epoch242 | Loss 0.08174478262662888 | Accuracy 1.0\n",
            "Epoch243 | Loss 0.08108651638031006 | Accuracy 1.0\n",
            "Epoch244 | Loss 0.08043594658374786 | Accuracy 1.0\n",
            "Epoch245 | Loss 0.07979296147823334 | Accuracy 1.0\n",
            "Epoch246 | Loss 0.07915749400854111 | Accuracy 1.0\n",
            "Epoch247 | Loss 0.07852940261363983 | Accuracy 1.0\n",
            "Epoch248 | Loss 0.07790859788656235 | Accuracy 1.0\n",
            "Epoch249 | Loss 0.07729499787092209 | Accuracy 1.0\n",
            "Epoch250 | Loss 0.07668846845626831 | Accuracy 1.0\n",
            "Epoch251 | Loss 0.07608894258737564 | Accuracy 1.0\n",
            "Epoch252 | Loss 0.07549633830785751 | Accuracy 1.0\n",
            "Epoch253 | Loss 0.07491050660610199 | Accuracy 1.0\n",
            "Epoch254 | Loss 0.07433140277862549 | Accuracy 1.0\n",
            "Epoch255 | Loss 0.07375894486904144 | Accuracy 1.0\n",
            "Epoch256 | Loss 0.07319299876689911 | Accuracy 1.0\n",
            "Epoch257 | Loss 0.0726335197687149 | Accuracy 1.0\n",
            "Epoch258 | Loss 0.07208038121461868 | Accuracy 1.0\n",
            "Epoch259 | Loss 0.07153352349996567 | Accuracy 1.0\n",
            "Epoch260 | Loss 0.0709928497672081 | Accuracy 1.0\n",
            "Epoch261 | Loss 0.0704582929611206 | Accuracy 1.0\n",
            "Epoch262 | Loss 0.06992974877357483 | Accuracy 1.0\n",
            "Epoch263 | Loss 0.0694071426987648 | Accuracy 1.0\n",
            "Epoch264 | Loss 0.06889038532972336 | Accuracy 1.0\n",
            "Epoch265 | Loss 0.06837942451238632 | Accuracy 1.0\n",
            "Epoch266 | Loss 0.06787417829036713 | Accuracy 1.0\n",
            "Epoch267 | Loss 0.06737454980611801 | Accuracy 1.0\n",
            "Epoch268 | Loss 0.06688045710325241 | Accuracy 1.0\n",
            "Epoch269 | Loss 0.06639185547828674 | Accuracy 1.0\n",
            "Epoch270 | Loss 0.06590864807367325 | Accuracy 1.0\n",
            "Epoch271 | Loss 0.06543076783418655 | Accuracy 1.0\n",
            "Epoch272 | Loss 0.06495817005634308 | Accuracy 1.0\n",
            "Epoch273 | Loss 0.06449073553085327 | Accuracy 1.0\n",
            "Epoch274 | Loss 0.06402841955423355 | Accuracy 1.0\n",
            "Epoch275 | Loss 0.06357116252183914 | Accuracy 1.0\n",
            "Epoch276 | Loss 0.06311888247728348 | Accuracy 1.0\n",
            "Epoch277 | Loss 0.06267151236534119 | Accuracy 1.0\n",
            "Epoch278 | Loss 0.062229011207818985 | Accuracy 1.0\n",
            "Epoch279 | Loss 0.06179128587245941 | Accuracy 1.0\n",
            "Epoch280 | Loss 0.061358269304037094 | Accuracy 1.0\n",
            "Epoch281 | Loss 0.060929927974939346 | Accuracy 1.0\n",
            "Epoch282 | Loss 0.060506172478199005 | Accuracy 1.0\n",
            "Epoch283 | Loss 0.06008695811033249 | Accuracy 1.0\n",
            "Epoch284 | Loss 0.059672221541404724 | Accuracy 1.0\n",
            "Epoch285 | Loss 0.05926189199090004 | Accuracy 1.0\n",
            "Epoch286 | Loss 0.05885593220591545 | Accuracy 1.0\n",
            "Epoch287 | Loss 0.05845426768064499 | Accuracy 1.0\n",
            "Epoch288 | Loss 0.058056849986314774 | Accuracy 1.0\n",
            "Epoch289 | Loss 0.05766361951828003 | Accuracy 1.0\n",
            "Epoch290 | Loss 0.05727452412247658 | Accuracy 1.0\n",
            "Epoch291 | Loss 0.05688950791954994 | Accuracy 1.0\n",
            "Epoch292 | Loss 0.05650850385427475 | Accuracy 1.0\n",
            "Epoch293 | Loss 0.05613148584961891 | Accuracy 1.0\n",
            "Epoch294 | Loss 0.05575838312506676 | Accuracy 1.0\n",
            "Epoch295 | Loss 0.0553891584277153 | Accuracy 1.0\n",
            "Epoch296 | Loss 0.05502374470233917 | Accuracy 1.0\n",
            "Epoch297 | Loss 0.05466210097074509 | Accuracy 1.0\n",
            "Epoch298 | Loss 0.05430418252944946 | Accuracy 1.0\n",
            "Epoch299 | Loss 0.05394991859793663 | Accuracy 1.0\n",
            "Epoch300 | Loss 0.05359930172562599 | Accuracy 1.0\n",
            "Epoch301 | Loss 0.05325225740671158 | Accuracy 1.0\n",
            "Epoch302 | Loss 0.05290873348712921 | Accuracy 1.0\n",
            "Epoch303 | Loss 0.0525687150657177 | Accuracy 1.0\n",
            "Epoch304 | Loss 0.05223212018609047 | Accuracy 1.0\n",
            "Epoch305 | Loss 0.05189893767237663 | Accuracy 1.0\n",
            "Epoch306 | Loss 0.05156908929347992 | Accuracy 1.0\n",
            "Epoch307 | Loss 0.051242560148239136 | Accuracy 1.0\n",
            "Epoch308 | Loss 0.0509193055331707 | Accuracy 1.0\n",
            "Epoch309 | Loss 0.05059927701950073 | Accuracy 1.0\n",
            "Epoch310 | Loss 0.05028242990374565 | Accuracy 1.0\n",
            "Epoch311 | Loss 0.04996872693300247 | Accuracy 1.0\n",
            "Epoch312 | Loss 0.04965813085436821 | Accuracy 1.0\n",
            "Epoch313 | Loss 0.04935059696435928 | Accuracy 1.0\n",
            "Epoch314 | Loss 0.049046099185943604 | Accuracy 1.0\n",
            "Epoch315 | Loss 0.04874458536505699 | Accuracy 1.0\n",
            "Epoch316 | Loss 0.04844601824879646 | Accuracy 1.0\n",
            "Epoch317 | Loss 0.04815037176012993 | Accuracy 1.0\n",
            "Epoch318 | Loss 0.04785760119557381 | Accuracy 1.0\n",
            "Epoch319 | Loss 0.04756767302751541 | Accuracy 1.0\n",
            "Epoch320 | Loss 0.047280553728342056 | Accuracy 1.0\n",
            "Epoch321 | Loss 0.04699619486927986 | Accuracy 1.0\n",
            "Epoch322 | Loss 0.04671458899974823 | Accuracy 1.0\n",
            "Epoch323 | Loss 0.04643566906452179 | Accuracy 1.0\n",
            "Epoch324 | Loss 0.04615943506360054 | Accuracy 1.0\n",
            "Epoch325 | Loss 0.045885827392339706 | Accuracy 1.0\n",
            "Epoch326 | Loss 0.0456148236989975 | Accuracy 1.0\n",
            "Epoch327 | Loss 0.045346394181251526 | Accuracy 1.0\n",
            "Epoch328 | Loss 0.045080509036779404 | Accuracy 1.0\n",
            "Epoch329 | Loss 0.04481712728738785 | Accuracy 1.0\n",
            "Epoch330 | Loss 0.04455622285604477 | Accuracy 1.0\n",
            "Epoch331 | Loss 0.04429776594042778 | Accuracy 1.0\n",
            "Epoch332 | Loss 0.04404173046350479 | Accuracy 1.0\n",
            "Epoch333 | Loss 0.043788082897663116 | Accuracy 1.0\n",
            "Epoch334 | Loss 0.04353678971529007 | Accuracy 1.0\n",
            "Epoch335 | Loss 0.04328783228993416 | Accuracy 1.0\n",
            "Epoch336 | Loss 0.043041180819272995 | Accuracy 1.0\n",
            "Epoch337 | Loss 0.042796798050403595 | Accuracy 1.0\n",
            "Epoch338 | Loss 0.042554669082164764 | Accuracy 1.0\n",
            "Epoch339 | Loss 0.04231475666165352 | Accuracy 1.0\n",
            "Epoch340 | Loss 0.04207703471183777 | Accuracy 1.0\n",
            "Epoch341 | Loss 0.04184148833155632 | Accuracy 1.0\n",
            "Epoch342 | Loss 0.04160808026790619 | Accuracy 1.0\n",
            "Epoch343 | Loss 0.04137678071856499 | Accuracy 1.0\n",
            "Epoch344 | Loss 0.041147585958242416 | Accuracy 1.0\n",
            "Epoch345 | Loss 0.040920455008745193 | Accuracy 1.0\n",
            "Epoch346 | Loss 0.04069535806775093 | Accuracy 1.0\n",
            "Epoch347 | Loss 0.04047228768467903 | Accuracy 1.0\n",
            "Epoch348 | Loss 0.04025120288133621 | Accuracy 1.0\n",
            "Epoch349 | Loss 0.040032099932432175 | Accuracy 1.0\n",
            "Epoch350 | Loss 0.03981493040919304 | Accuracy 1.0\n",
            "Epoch351 | Loss 0.0395996980369091 | Accuracy 1.0\n",
            "Epoch352 | Loss 0.039386358112096786 | Accuracy 1.0\n",
            "Epoch353 | Loss 0.03917490690946579 | Accuracy 1.0\n",
            "Epoch354 | Loss 0.038965314626693726 | Accuracy 1.0\n",
            "Epoch355 | Loss 0.038757551461458206 | Accuracy 1.0\n",
            "Epoch356 | Loss 0.03855160251259804 | Accuracy 1.0\n",
            "Epoch357 | Loss 0.038347452878952026 | Accuracy 1.0\n",
            "Epoch358 | Loss 0.038145072758197784 | Accuracy 1.0\n",
            "Epoch359 | Loss 0.03794444724917412 | Accuracy 1.0\n",
            "Epoch360 | Loss 0.03774556145071983 | Accuracy 1.0\n",
            "Epoch361 | Loss 0.037548381835222244 | Accuracy 1.0\n",
            "Epoch362 | Loss 0.037352897226810455 | Accuracy 1.0\n",
            "Epoch363 | Loss 0.03715909644961357 | Accuracy 1.0\n",
            "Epoch364 | Loss 0.03696694225072861 | Accuracy 1.0\n",
            "Epoch365 | Loss 0.036776427179574966 | Accuracy 1.0\n",
            "Epoch366 | Loss 0.03658752515912056 | Accuracy 1.0\n",
            "Epoch367 | Loss 0.03640023246407509 | Accuracy 1.0\n",
            "Epoch368 | Loss 0.03621451556682587 | Accuracy 1.0\n",
            "Epoch369 | Loss 0.0360303595662117 | Accuracy 1.0\n",
            "Epoch370 | Loss 0.03584775701165199 | Accuracy 1.0\n",
            "Epoch371 | Loss 0.035666678100824356 | Accuracy 1.0\n",
            "Epoch372 | Loss 0.03548712283372879 | Accuracy 1.0\n",
            "Epoch373 | Loss 0.035309046506881714 | Accuracy 1.0\n",
            "Epoch374 | Loss 0.035132456570863724 | Accuracy 1.0\n",
            "Epoch375 | Loss 0.03495732694864273 | Accuracy 1.0\n",
            "Epoch376 | Loss 0.03478365018963814 | Accuracy 1.0\n",
            "Epoch377 | Loss 0.034611400216817856 | Accuracy 1.0\n",
            "Epoch378 | Loss 0.03444056212902069 | Accuracy 1.0\n",
            "Epoch379 | Loss 0.03427112475037575 | Accuracy 1.0\n",
            "Epoch380 | Loss 0.03410307317972183 | Accuracy 1.0\n",
            "Epoch381 | Loss 0.03393638879060745 | Accuracy 1.0\n",
            "Epoch382 | Loss 0.033771056681871414 | Accuracy 1.0\n",
            "Epoch383 | Loss 0.033607058227062225 | Accuracy 1.0\n",
            "Epoch384 | Loss 0.033444393426179886 | Accuracy 1.0\n",
            "Epoch385 | Loss 0.03328302875161171 | Accuracy 1.0\n",
            "Epoch386 | Loss 0.033122967928647995 | Accuracy 1.0\n",
            "Epoch387 | Loss 0.03296418860554695 | Accuracy 1.0\n",
            "Epoch388 | Loss 0.032806675881147385 | Accuracy 1.0\n",
            "Epoch389 | Loss 0.0326504148542881 | Accuracy 1.0\n",
            "Epoch390 | Loss 0.032495394349098206 | Accuracy 1.0\n",
            "Epoch391 | Loss 0.0323416069149971 | Accuracy 1.0\n",
            "Epoch392 | Loss 0.032189033925533295 | Accuracy 1.0\n",
            "Epoch393 | Loss 0.03203766420483589 | Accuracy 1.0\n",
            "Epoch394 | Loss 0.0318874791264534 | Accuracy 1.0\n",
            "Epoch395 | Loss 0.03173847123980522 | Accuracy 1.0\n",
            "Epoch396 | Loss 0.031590621918439865 | Accuracy 1.0\n",
            "Epoch397 | Loss 0.03144393116235733 | Accuracy 1.0\n",
            "Epoch398 | Loss 0.031298380345106125 | Accuracy 1.0\n",
            "Epoch399 | Loss 0.031153954565525055 | Accuracy 1.0\n",
            "Epoch400 | Loss 0.031010646373033524 | Accuracy 1.0\n",
            "Epoch401 | Loss 0.030868440866470337 | Accuracy 1.0\n",
            "Epoch402 | Loss 0.030727330595254898 | Accuracy 1.0\n",
            "Epoch403 | Loss 0.030587302520871162 | Accuracy 1.0\n",
            "Epoch404 | Loss 0.030448341742157936 | Accuracy 1.0\n",
            "Epoch405 | Loss 0.03031044453382492 | Accuracy 1.0\n",
            "Epoch406 | Loss 0.030173595994710922 | Accuracy 1.0\n",
            "Epoch407 | Loss 0.03003777377307415 | Accuracy 1.0\n",
            "Epoch408 | Loss 0.02990298718214035 | Accuracy 1.0\n",
            "Epoch409 | Loss 0.02976921945810318 | Accuracy 1.0\n",
            "Epoch410 | Loss 0.029636450111865997 | Accuracy 1.0\n",
            "Epoch411 | Loss 0.02950468473136425 | Accuracy 1.0\n",
            "Epoch412 | Loss 0.02937389723956585 | Accuracy 1.0\n",
            "Epoch413 | Loss 0.029244089499115944 | Accuracy 1.0\n",
            "Epoch414 | Loss 0.02911524660885334 | Accuracy 1.0\n",
            "Epoch415 | Loss 0.028987359255552292 | Accuracy 1.0\n",
            "Epoch416 | Loss 0.02886042185127735 | Accuracy 1.0\n",
            "Epoch417 | Loss 0.028734421357512474 | Accuracy 1.0\n",
            "Epoch418 | Loss 0.028609342873096466 | Accuracy 1.0\n",
            "Epoch419 | Loss 0.028485184535384178 | Accuracy 1.0\n",
            "Epoch420 | Loss 0.028361931443214417 | Accuracy 1.0\n",
            "Epoch421 | Loss 0.02823958732187748 | Accuracy 1.0\n",
            "Epoch422 | Loss 0.028118127956986427 | Accuracy 1.0\n",
            "Epoch423 | Loss 0.02799754962325096 | Accuracy 1.0\n",
            "Epoch424 | Loss 0.02787785418331623 | Accuracy 1.0\n",
            "Epoch425 | Loss 0.027759013697504997 | Accuracy 1.0\n",
            "Epoch426 | Loss 0.02764103375375271 | Accuracy 1.0\n",
            "Epoch427 | Loss 0.027523895725607872 | Accuracy 1.0\n",
            "Epoch428 | Loss 0.027407599613070488 | Accuracy 1.0\n",
            "Epoch429 | Loss 0.027292141690850258 | Accuracy 1.0\n",
            "Epoch430 | Loss 0.02717750519514084 | Accuracy 1.0\n",
            "Epoch431 | Loss 0.027063684538006783 | Accuracy 1.0\n",
            "Epoch432 | Loss 0.026950664818286896 | Accuracy 1.0\n",
            "Epoch433 | Loss 0.026838449761271477 | Accuracy 1.0\n",
            "Epoch434 | Loss 0.02672702446579933 | Accuracy 1.0\n",
            "Epoch435 | Loss 0.02661638706922531 | Accuracy 1.0\n",
            "Epoch436 | Loss 0.02650652825832367 | Accuracy 1.0\n",
            "Epoch437 | Loss 0.026397429406642914 | Accuracy 1.0\n",
            "Epoch438 | Loss 0.026289092376828194 | Accuracy 1.0\n",
            "Epoch439 | Loss 0.02618151716887951 | Accuracy 1.0\n",
            "Epoch440 | Loss 0.026074690744280815 | Accuracy 1.0\n",
            "Epoch441 | Loss 0.025968600064516068 | Accuracy 1.0\n",
            "Epoch442 | Loss 0.02586323767900467 | Accuracy 1.0\n",
            "Epoch443 | Loss 0.025758614763617516 | Accuracy 1.0\n",
            "Epoch444 | Loss 0.02565470151603222 | Accuracy 1.0\n",
            "Epoch445 | Loss 0.025551505386829376 | Accuracy 1.0\n",
            "Epoch446 | Loss 0.025449011474847794 | Accuracy 1.0\n",
            "Epoch447 | Loss 0.02534721978008747 | Accuracy 1.0\n",
            "Epoch448 | Loss 0.025246119126677513 | Accuracy 1.0\n",
            "Epoch449 | Loss 0.02514570765197277 | Accuracy 1.0\n",
            "Epoch450 | Loss 0.025045977905392647 | Accuracy 1.0\n",
            "Epoch451 | Loss 0.0249469131231308 | Accuracy 1.0\n",
            "Epoch452 | Loss 0.024848520755767822 | Accuracy 1.0\n",
            "Epoch453 | Loss 0.024750789627432823 | Accuracy 1.0\n",
            "Epoch454 | Loss 0.024653714150190353 | Accuracy 1.0\n",
            "Epoch455 | Loss 0.024557288736104965 | Accuracy 1.0\n",
            "Epoch456 | Loss 0.024461504071950912 | Accuracy 1.0\n",
            "Epoch457 | Loss 0.024366365745663643 | Accuracy 1.0\n",
            "Epoch458 | Loss 0.024271849542856216 | Accuracy 1.0\n",
            "Epoch459 | Loss 0.02417795918881893 | Accuracy 1.0\n",
            "Epoch460 | Loss 0.02408468909561634 | Accuracy 1.0\n",
            "Epoch461 | Loss 0.023992037400603294 | Accuracy 1.0\n",
            "Epoch462 | Loss 0.0238999892026186 | Accuracy 1.0\n",
            "Epoch463 | Loss 0.023808544501662254 | Accuracy 1.0\n",
            "Epoch464 | Loss 0.02371770516037941 | Accuracy 1.0\n",
            "Epoch465 | Loss 0.023627450689673424 | Accuracy 1.0\n",
            "Epoch466 | Loss 0.02353779226541519 | Accuracy 1.0\n",
            "Epoch467 | Loss 0.023448707535862923 | Accuracy 1.0\n",
            "Epoch468 | Loss 0.02336020953953266 | Accuracy 1.0\n",
            "Epoch469 | Loss 0.02327226661145687 | Accuracy 1.0\n",
            "Epoch470 | Loss 0.023184899240732193 | Accuracy 1.0\n",
            "Epoch471 | Loss 0.023098092526197433 | Accuracy 1.0\n",
            "Epoch472 | Loss 0.023011840879917145 | Accuracy 1.0\n",
            "Epoch473 | Loss 0.022926148027181625 | Accuracy 1.0\n",
            "Epoch474 | Loss 0.022840997204184532 | Accuracy 1.0\n",
            "Epoch475 | Loss 0.022756386548280716 | Accuracy 1.0\n",
            "Epoch476 | Loss 0.022672314196825027 | Accuracy 1.0\n",
            "Epoch477 | Loss 0.02258877456188202 | Accuracy 1.0\n",
            "Epoch478 | Loss 0.022505762055516243 | Accuracy 1.0\n",
            "Epoch479 | Loss 0.022423280403017998 | Accuracy 1.0\n",
            "Epoch480 | Loss 0.022341307252645493 | Accuracy 1.0\n",
            "Epoch481 | Loss 0.022259851917624474 | Accuracy 1.0\n",
            "Epoch482 | Loss 0.022178903222084045 | Accuracy 1.0\n",
            "Epoch483 | Loss 0.022098461166024208 | Accuracy 1.0\n",
            "Epoch484 | Loss 0.022018523886799812 | Accuracy 1.0\n",
            "Epoch485 | Loss 0.021939082071185112 | Accuracy 1.0\n",
            "Epoch486 | Loss 0.021860135719180107 | Accuracy 1.0\n",
            "Epoch487 | Loss 0.021781669929623604 | Accuracy 1.0\n",
            "Epoch488 | Loss 0.021703695878386497 | Accuracy 1.0\n",
            "Epoch489 | Loss 0.021626194939017296 | Accuracy 1.0\n",
            "Epoch490 | Loss 0.021549168974161148 | Accuracy 1.0\n",
            "Epoch491 | Loss 0.021472619846463203 | Accuracy 1.0\n",
            "Epoch492 | Loss 0.021396540105342865 | Accuracy 1.0\n",
            "Epoch493 | Loss 0.021320916712284088 | Accuracy 1.0\n",
            "Epoch494 | Loss 0.021245760843157768 | Accuracy 1.0\n",
            "Epoch495 | Loss 0.021171053871512413 | Accuracy 1.0\n",
            "Epoch496 | Loss 0.02109679952263832 | Accuracy 1.0\n",
            "Epoch497 | Loss 0.021022997796535492 | Accuracy 1.0\n",
            "Epoch498 | Loss 0.02094964124262333 | Accuracy 1.0\n",
            "Epoch499 | Loss 0.020876726135611534 | Accuracy 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WX2PSXnTDiNi"
      },
      "source": [
        "## Visualize the final node embeddings\n",
        "Visualize your final embedding here! \n",
        "You can visually compare the figure with the previous embedding figure. \n",
        "After training, you should oberserve that the two classes are more evidently separated. \n",
        "This is a great sanitity check for your implementation as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtNgl4VhYKow",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "c945a148-677c-4f69-b135-ee59d13f9c25"
      },
      "source": [
        "# Visualize the final learned embedding\n",
        "visualize_emb(emb)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTNyrAoSVeq9"
      },
      "source": [
        "# Submission"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_E7J_GkVhY_"
      },
      "source": [
        "In order to get credit, you must go submit your answers on Gradescope."
      ]
    }
  ]
}